{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK7JqvWShJy7"
      },
      "source": [
        "# Non-Linear Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "143J4vMehLRf"
      },
      "source": [
        "In this notebook we will build binary classification model using logistic regression technique. **Non-Linear** here refers to, where the data is separable by non-linear decision boundary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWFLzUV5hOdN"
      },
      "source": [
        "## Outline\n",
        "\n",
        "- [1 - Packages](#1)\n",
        "\n",
        "- [2 - Dataset](#2)\n",
        "\n",
        "- [3 - Non-Linear Binary Classification Model](#3)\n",
        "    - [3.1 Scikit-Learn Model](#3point1)\n",
        "    - [3.2 Numpy Model](#3point2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-47ny6j3hRDi"
      },
      "source": [
        "<a id=\"1\"></a>\n",
        "## 1 - Packages\n",
        "\n",
        "Below are the packages/libraries that we are going to use in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y0xixaBCMDK"
      },
      "outputs": [],
      "source": [
        "# Importing necessary packages/libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from binary_classification_model import LogisticRegression_\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1oeStZahx-y"
      },
      "source": [
        "<a id=\"2\"></a>\n",
        "## 2 - Dataset\n",
        "\n",
        "The binary classification dataset that we are going to use is from [Kaggle](https://www.kaggle.com/datasets/l3llff/banana), which was provided by **L3LLFF**.\n",
        "\n",
        "The dataset is downloaded and stored in `non_linear_binary_class_dataset` folder, the folder contains a CSV file named `banana_quality.csv` that we are going to use to train, validate, and test our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtH4EHPuh0qQ"
      },
      "source": [
        "Let's load the dataset into pandas dataframe, and get the overview of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AWk04VxKef2C",
        "outputId": "88fa341c-a632-4b1c-e4ff-3bd7f4848b50"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.136022791892043,\n        \"min\": -7.9980736,\n        \"max\": 7.9708004,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -1.1823753,\n          -2.1902218,\n          -0.01742254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0159342527719275,\n        \"min\": -8.283002,\n        \"max\": 5.679692,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -1.5233536,\n          -2.8090863,\n          1.1875557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sweetness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9484548834162474,\n        \"min\": -6.4340215,\n        \"max\": 7.539374,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -1.3909012,\n          -1.3944167,\n          4.7572994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Softness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.065215944309168,\n        \"min\": -6.9593196,\n        \"max\": 8.241555,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -0.850838,\n          2.6063178,\n          1.0700845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HarvestTime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9966607874097047,\n        \"min\": -7.5700083,\n        \"max\": 6.29328,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -0.13659394,\n          -0.016427217,\n          -2.5047512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ripeness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.11428937214284,\n        \"min\": -7.4231553,\n        \"max\": 7.2490335,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          2.3312151,\n          5.5374675,\n          -1.0434868\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2934666385409743,\n        \"min\": -8.226977,\n        \"max\": 7.4116335,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -1.8286724,\n          -4.9408426,\n          2.5416763\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quality\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Bad\",\n          \"Good\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3293727d-872a-4088-b16b-e2193a195da6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Sweetness</th>\n",
              "      <th>Softness</th>\n",
              "      <th>HarvestTime</th>\n",
              "      <th>Ripeness</th>\n",
              "      <th>Acidity</th>\n",
              "      <th>Quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.924968</td>\n",
              "      <td>0.468078</td>\n",
              "      <td>3.077832</td>\n",
              "      <td>-1.472177</td>\n",
              "      <td>0.294799</td>\n",
              "      <td>2.435570</td>\n",
              "      <td>0.271290</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.409751</td>\n",
              "      <td>0.486870</td>\n",
              "      <td>0.346921</td>\n",
              "      <td>-2.495099</td>\n",
              "      <td>-0.892213</td>\n",
              "      <td>2.067549</td>\n",
              "      <td>0.307325</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.357607</td>\n",
              "      <td>1.483176</td>\n",
              "      <td>1.568452</td>\n",
              "      <td>-2.645145</td>\n",
              "      <td>-0.647267</td>\n",
              "      <td>3.090643</td>\n",
              "      <td>1.427322</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.868524</td>\n",
              "      <td>1.566201</td>\n",
              "      <td>1.889605</td>\n",
              "      <td>-1.273761</td>\n",
              "      <td>-1.006278</td>\n",
              "      <td>1.873001</td>\n",
              "      <td>0.477862</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.651825</td>\n",
              "      <td>1.319199</td>\n",
              "      <td>-0.022459</td>\n",
              "      <td>-1.209709</td>\n",
              "      <td>-1.430692</td>\n",
              "      <td>1.078345</td>\n",
              "      <td>2.812442</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>-6.414403</td>\n",
              "      <td>0.723565</td>\n",
              "      <td>1.134953</td>\n",
              "      <td>2.952763</td>\n",
              "      <td>0.297928</td>\n",
              "      <td>-0.156946</td>\n",
              "      <td>2.398091</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>0.851143</td>\n",
              "      <td>-2.217875</td>\n",
              "      <td>-2.812175</td>\n",
              "      <td>0.489249</td>\n",
              "      <td>-1.323410</td>\n",
              "      <td>-2.316883</td>\n",
              "      <td>2.113136</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>1.422722</td>\n",
              "      <td>-1.907665</td>\n",
              "      <td>-2.532364</td>\n",
              "      <td>0.964976</td>\n",
              "      <td>-0.562375</td>\n",
              "      <td>-1.834765</td>\n",
              "      <td>0.697361</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>-2.131904</td>\n",
              "      <td>-2.742600</td>\n",
              "      <td>-1.008029</td>\n",
              "      <td>2.126946</td>\n",
              "      <td>-0.802632</td>\n",
              "      <td>-3.580266</td>\n",
              "      <td>0.423569</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>-2.660879</td>\n",
              "      <td>-2.044666</td>\n",
              "      <td>0.159026</td>\n",
              "      <td>1.499706</td>\n",
              "      <td>-1.581856</td>\n",
              "      <td>-1.605859</td>\n",
              "      <td>1.435644</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3293727d-872a-4088-b16b-e2193a195da6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3293727d-872a-4088-b16b-e2193a195da6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3293727d-872a-4088-b16b-e2193a195da6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8b61743c-72e1-4b43-b0fb-306ca5f717e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b61743c-72e1-4b43-b0fb-306ca5f717e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8b61743c-72e1-4b43-b0fb-306ca5f717e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e4a8f360-8991-4737-8f8d-c5325de87f8f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e4a8f360-8991-4737-8f8d-c5325de87f8f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Size    Weight  Sweetness  Softness  HarvestTime  Ripeness  \\\n",
              "0    -1.924968  0.468078   3.077832 -1.472177     0.294799  2.435570   \n",
              "1    -2.409751  0.486870   0.346921 -2.495099    -0.892213  2.067549   \n",
              "2    -0.357607  1.483176   1.568452 -2.645145    -0.647267  3.090643   \n",
              "3    -0.868524  1.566201   1.889605 -1.273761    -1.006278  1.873001   \n",
              "4     0.651825  1.319199  -0.022459 -1.209709    -1.430692  1.078345   \n",
              "...        ...       ...        ...       ...          ...       ...   \n",
              "7995 -6.414403  0.723565   1.134953  2.952763     0.297928 -0.156946   \n",
              "7996  0.851143 -2.217875  -2.812175  0.489249    -1.323410 -2.316883   \n",
              "7997  1.422722 -1.907665  -2.532364  0.964976    -0.562375 -1.834765   \n",
              "7998 -2.131904 -2.742600  -1.008029  2.126946    -0.802632 -3.580266   \n",
              "7999 -2.660879 -2.044666   0.159026  1.499706    -1.581856 -1.605859   \n",
              "\n",
              "       Acidity Quality  \n",
              "0     0.271290    Good  \n",
              "1     0.307325    Good  \n",
              "2     1.427322    Good  \n",
              "3     0.477862    Good  \n",
              "4     2.812442    Good  \n",
              "...        ...     ...  \n",
              "7995  2.398091     Bad  \n",
              "7996  2.113136     Bad  \n",
              "7997  0.697361     Bad  \n",
              "7998  0.423569     Bad  \n",
              "7999  1.435644     Bad  \n",
              "\n",
              "[8000 rows x 8 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading the dataset into pandas dataframe\n",
        "data = pd.read_csv(\"non_linear_binary_class_dataset/banana_quality.csv\")\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxGZ70rwh58S"
      },
      "source": [
        "We have **8,000** rows and **8** columns, from which we are going to split the dataset into **60%** training, **20%** cross-validation, and **20%** testing sets. The first **7** columns are features variables and the last one is target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAE5gjRGh6ww"
      },
      "source": [
        "While the dataset is clean, we will still going to look for any missing/NaN values in a dataset, and view the class distribution of the target variable. We also going to convert the target variable values from **Good** and **Bad** to **1** and **0**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "Pz8YIDl-h9Uk",
        "outputId": "a1347f90-0520-4c99-892b-5dd9552a9488"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Size</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sweetness</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Softness</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HarvestTime</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ripeness</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acidity</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Quality</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> bool</label>"
            ],
            "text/plain": [
              "Size           False\n",
              "Weight         False\n",
              "Sweetness      False\n",
              "Softness       False\n",
              "HarvestTime    False\n",
              "Ripeness       False\n",
              "Acidity        False\n",
              "Quality        False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking for any missing/NaN values\n",
        "data.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKRJOGM0iBJa",
        "outputId": "05cd4f3a-fb50-44cc-8a2d-4c3cbb48793d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['Bad', 'Good'], dtype=object), array([3994, 4006]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Viewing the class distribution in target variable\n",
        "np.unique(data[\"Quality\"], return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUSNLIe6iD00"
      },
      "source": [
        "The dataset has no missing values, and also not has imbalanced class distribution. Let's now convert the dataset into numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zR7r2pNiFkb",
        "outputId": "1151ba2d-5a10-433b-9c77-d87366c57ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X.shape: (8000, 7) & Y.shape: (8000, 1)\n"
          ]
        }
      ],
      "source": [
        "# Converting the data into numpy arrays\n",
        "X = data.to_numpy()[:, 0:7]\n",
        "Y = np.where(data[\"Quality\"] == \"Good\", 1, 0).reshape(-1, 1)\n",
        "\n",
        "print(f\"X.shape: {X.shape} & Y.shape: {Y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DMmcVC5iHte",
        "outputId": "16006799-8708-4a47-fcbe-c3d22cf150ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set Size: (4800, 7)\n",
            "Cross-Validation Set Size: (1600, 7)\n",
            "Test Set Size: (1600, 7)\n"
          ]
        }
      ],
      "source": [
        "# Splitting the dataset into training (60%) and temp (40%)\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.4, random_state=42, stratify=Y)\n",
        "\n",
        "# Splitting the temp data into cross-validation (50%) and test (50%)\n",
        "X_cv, X_test, Y_cv, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42, stratify=Y_temp)\n",
        "\n",
        "print(f\"Training Set Size: {X_train.shape}\")\n",
        "print(f\"Cross-Validation Set Size: {X_cv.shape}\")\n",
        "print(f\"Test Set Size: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2RqI0CCiLBt"
      },
      "source": [
        "<a id=\"3\"></a>\n",
        "## 3 - Non-Linear Binary Classifcation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP1Pu8yniLvk"
      },
      "source": [
        "<a id=\"3point1\"></a>\n",
        "### 3.1 Scikit-Learn Model\n",
        "\n",
        "Since we do not know whether the data is suitable for our goal (_e.g. is the data separable by non-linear dicision boundary_), we will first build few models linear and non-linear's using scikit-learn, and after determining the optimal model hopefully the non-linear binary classification model, we will then build our custom model using numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQoQ21TsesNa",
        "outputId": "32de5034-9e2d-4776-e72a-85dd11b8f39f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with polynomial degree 1\n",
            "Train Accuracy: 0.8781, Cross-Validation Accuracy: 0.8850\n",
            "\n",
            "Training model with polynomial degree 2\n",
            "Train Accuracy: 0.9640, Cross-Validation Accuracy: 0.9650\n",
            "\n",
            "Training model with polynomial degree 3\n",
            "Train Accuracy: 0.9829, Cross-Validation Accuracy: 0.9675\n",
            "\n",
            "Training model with polynomial degree 4\n",
            "Train Accuracy: 0.9877, Cross-Validation Accuracy: 0.9694\n",
            "\n",
            "Training model with polynomial degree 5\n",
            "Train Accuracy: 0.9875, Cross-Validation Accuracy: 0.9637\n",
            "\n",
            "Training model with polynomial degree 6\n",
            "Train Accuracy: 0.9865, Cross-Validation Accuracy: 0.9681\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Dictionary to store trained models with their polynomial degree as the key\n",
        "models = {}\n",
        "\n",
        "# Training models of (Degrees 1 to 6) -> (Degree 1 means linear model)\n",
        "for degree in range(1, 7):\n",
        "    print(f\"Training model with polynomial degree {degree}\")\n",
        "\n",
        "    # Creating a pipeline with PolynomialFeatures + StandardScaler + SGDClassifier\n",
        "    model_pipeline = Pipeline(\n",
        "        steps=[\n",
        "        (\"poly_features\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"sgd_classifier\", SGDClassifier(loss=\"log_loss\", max_iter=10000, penalty=None, random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Training the model\n",
        "    model_pipeline.fit(X_train, Y_train.flatten())\n",
        "\n",
        "    # Evaluating on training and cross-validation sets\n",
        "    train_accuracy = accuracy_score(Y_train, model_pipeline.predict(X_train).reshape(-1, 1))\n",
        "    cv_accuracy = accuracy_score(Y_cv, model_pipeline.predict(X_cv).reshape(-1, 1))\n",
        "\n",
        "    print(f\"Train Accuracy: {train_accuracy:.4f}, Cross-Validation Accuracy: {cv_accuracy:.4f}\\n\")\n",
        "\n",
        "    # Storing the trained model with the polynomial degree as the key\n",
        "    models[f\"degree_{degree}\"] = model_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQMLlzj9rbZf"
      },
      "source": [
        "The results indicate that the dataset is **not linearly separable**, as higher-degree models improve performance.  \n",
        "\n",
        "- **Degree 1** performs poorly (**Train: 87.81%**, **CV: 88.50%**), proving a linear model is insufficient.  \n",
        "- **Degree 2** achieves **strong and stable accuracy (Train: 96.40%, CV: 96.50%)**, showing it captures necessary non-linearity.  \n",
        "- **Degree 3-6** improve train accuracy but **CV accuracy stabilizes or slightly drops**, suggesting overfitting.  \n",
        "\n",
        "Thus, the **degree 2 model** is the best choice, offering **high efficiency, stability, and accuracy**. And it proves that the dataset is suitable for our goal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56MDCxDrsqb9"
      },
      "source": [
        "Now let's evaluate the optimal model on testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "5SmiTQd11MUZ",
        "outputId": "53f98965-cbfa-4c45-d408-3f6de6737431"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;poly_features&#x27;, PolynomialFeatures(include_bias=False)),\n",
              "                (&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;sgd_classifier&#x27;,\n",
              "                 SGDClassifier(loss=&#x27;log_loss&#x27;, max_iter=10000, penalty=None,\n",
              "                               random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;poly_features&#x27;, PolynomialFeatures(include_bias=False)),\n",
              "                (&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;sgd_classifier&#x27;,\n",
              "                 SGDClassifier(loss=&#x27;log_loss&#x27;, max_iter=10000, penalty=None,\n",
              "                               random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PolynomialFeatures</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\">?<span>Documentation for PolynomialFeatures</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>PolynomialFeatures(include_bias=False)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SGDClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;, max_iter=10000, penalty=None, random_state=42)</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('poly_features', PolynomialFeatures(include_bias=False)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('sgd_classifier',\n",
              "                 SGDClassifier(loss='log_loss', max_iter=10000, penalty=None,\n",
              "                               random_state=42))])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieving the optimal model\n",
        "model = models[\"degree_2\"]\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COniP53Ps4-3",
        "outputId": "a182b73e-b8d1-407e-cce4-9e6153b525a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9550\n"
          ]
        }
      ],
      "source": [
        "# Making prediction on test data and calculating the accuracy\n",
        "test_accuracy = accuracy_score(Y_test, model.predict(X_test).reshape(-1, 1))\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8JTQASeuahf"
      },
      "source": [
        "The test accuracy is close to train and validation accuracy. This completes our goal of building a non-linear binary classification model using scikit-learn library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsTR9cPBu4xH"
      },
      "source": [
        "<a id=\"3point2\"></a>\n",
        "### 3.2 Numpy Model\n",
        "\n",
        "Now we will build non-linear binary classification model using numpy library. We will use vectorized approach for efficient implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgI4G0Su9cs"
      },
      "source": [
        "The non-linear binary classification model also called logistic regression can be represented as:\n",
        "\n",
        "$$ Z = f(X) = X \\cdot W + B \\tag{1} $$  \n",
        "$$ \\hat{Y} = \\sigma(Z) = \\frac{1}{1 + e^{-Z}} \\tag{2} $$  \n",
        "\n",
        "where,  \n",
        "- $Z$ is the linear combination of input features, weights, and bias.  \n",
        "- $X$ is the input feature matrix.  \n",
        "- $W$ is the weight matrix.  \n",
        "- $B$ is the bias matrix.\n",
        "- $\\hat{Y}$ is the predicted probability matrix.\n",
        "- $\\sigma(Z)$ is the sigmoid activation function whose input is $Z$.  \n",
        "\n",
        "The cost function for our model will be **Binary Cross-Entropy (Log Loss)**:\n",
        "\n",
        "$$ C = J(W, B) = -\\frac{1}{m} * \\sum \\left[Y * \\ln(\\hat{Y}) + (1 - Y) * \\ln(1 - \\hat{Y}) \\right] \\tag{3} $$\n",
        "\n",
        "where,  \n",
        "- $m$ is the number of training examples.  \n",
        "- $Y$ is the actual target variable matrix.  \n",
        "\n",
        "To train our model, we will use **gradient descent**, updating weights and bias as follows:\n",
        "\n",
        "$$ W = W - \\alpha * \\frac{\\partial J(W, B)}{\\partial W} \\tag{4} $$\n",
        "$$ B = B - \\alpha * \\frac{\\partial J(W, B)}{\\partial B} \\tag{5} $$\n",
        "\n",
        "where,  \n",
        "$$ \\frac{\\partial J(W, B)}{\\partial W}  = \\frac{1}{m} * X^{T} \\cdot (\\hat{Y} - Y) \\tag{6} $$  \n",
        "$$ \\frac{\\partial J(W, B)}{\\partial B}  = \\frac{1}{m} * \\sum (\\hat{Y} - Y) \\tag{7} $$  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJy1qEgyv56J"
      },
      "source": [
        "_**NOTE:** All the code implementation of the above is in `binary_classification_model.py` file_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z1BG4w6tGY8",
        "outputId": "0df1c2d4-0e1b-4f6d-e09a-1b6b1e63a6d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 1/1000\n",
            "Cost: 0.6931471803599453\n",
            "\n",
            "Iteration: 2/1000\n",
            "Cost: 0.19588484481261173\n",
            "\n",
            "Iteration: 3/1000\n",
            "Cost: 0.15927233707365807\n",
            "\n",
            "Iteration: 4/1000\n",
            "Cost: 0.14802217725214087\n",
            "\n",
            "Iteration: 5/1000\n",
            "Cost: 0.1410438484040771\n",
            "\n",
            "Iteration: 6/1000\n",
            "Cost: 0.13602652674613763\n",
            "\n",
            "Iteration: 7/1000\n",
            "Cost: 0.13222232726269745\n",
            "\n",
            "Iteration: 8/1000\n",
            "Cost: 0.12925931737222077\n",
            "\n",
            "Iteration: 9/1000\n",
            "Cost: 0.12690709102140832\n",
            "\n",
            "Iteration: 10/1000\n",
            "Cost: 0.12500663750981136\n",
            "\n",
            "Iteration: 11/1000\n",
            "Cost: 0.12344338651814221\n",
            "\n",
            "Iteration: 12/1000\n",
            "Cost: 0.1221340019989874\n",
            "\n",
            "Iteration: 13/1000\n",
            "Cost: 0.1210180040130337\n",
            "\n",
            "Iteration: 14/1000\n",
            "Cost: 0.12005160540138429\n",
            "\n",
            "Iteration: 15/1000\n",
            "Cost: 0.1192030409786031\n",
            "\n",
            "Iteration: 16/1000\n",
            "Cost: 0.11844909641745495\n",
            "\n",
            "Iteration: 17/1000\n",
            "Cost: 0.11777259890691218\n",
            "\n",
            "Iteration: 18/1000\n",
            "Cost: 0.11716064284234447\n",
            "\n",
            "Iteration: 19/1000\n",
            "Cost: 0.11660335277716899\n",
            "\n",
            "Iteration: 20/1000\n",
            "Cost: 0.11609302658550646\n",
            "\n",
            "Iteration: 21/1000\n",
            "Cost: 0.11562354213399535\n",
            "\n",
            "Iteration: 22/1000\n",
            "Cost: 0.11518994444915241\n",
            "\n",
            "Iteration: 23/1000\n",
            "Cost: 0.11478815593750523\n",
            "\n",
            "Iteration: 24/1000\n",
            "Cost: 0.11441477055560645\n",
            "\n",
            "Iteration: 25/1000\n",
            "Cost: 0.11406690553369613\n",
            "\n",
            "Iteration: 26/1000\n",
            "Cost: 0.11374209287959834\n",
            "\n",
            "Iteration: 27/1000\n",
            "Cost: 0.11343819867344677\n",
            "\n",
            "Iteration: 28/1000\n",
            "Cost: 0.11315336202344398\n",
            "\n",
            "Iteration: 29/1000\n",
            "Cost: 0.11288594812677696\n",
            "\n",
            "Iteration: 30/1000\n",
            "Cost: 0.11263451160122609\n",
            "\n",
            "Iteration: 31/1000\n",
            "Cost: 0.11239776741062232\n",
            "\n",
            "Iteration: 32/1000\n",
            "Cost: 0.11217456749170585\n",
            "\n",
            "Iteration: 33/1000\n",
            "Cost: 0.1119638817263799\n",
            "\n",
            "Iteration: 34/1000\n",
            "Cost: 0.11176478227409177\n",
            "\n",
            "Iteration: 35/1000\n",
            "Cost: 0.1115764305382741\n",
            "\n",
            "Iteration: 36/1000\n",
            "Cost: 0.11139806622422588\n",
            "\n",
            "Iteration: 37/1000\n",
            "Cost: 0.11122899807731794\n",
            "\n",
            "Iteration: 38/1000\n",
            "Cost: 0.11106859598590324\n",
            "\n",
            "Iteration: 39/1000\n",
            "Cost: 0.1109162842035749\n",
            "\n",
            "Iteration: 40/1000\n",
            "Cost: 0.11077153549777462\n",
            "\n",
            "Iteration: 41/1000\n",
            "Cost: 0.11063386607126637\n",
            "\n",
            "Iteration: 42/1000\n",
            "Cost: 0.11050283113317072\n",
            "\n",
            "Iteration: 43/1000\n",
            "Cost: 0.11037802101956894\n",
            "\n",
            "Iteration: 44/1000\n",
            "Cost: 0.11025905778189592\n",
            "\n",
            "Iteration: 45/1000\n",
            "Cost: 0.11014559217570692\n",
            "\n",
            "Iteration: 46/1000\n",
            "Cost: 0.11003730099384557\n",
            "\n",
            "Iteration: 47/1000\n",
            "Cost: 0.10993388469723193\n",
            "\n",
            "Iteration: 48/1000\n",
            "Cost: 0.10983506530393847\n",
            "\n",
            "Iteration: 49/1000\n",
            "Cost: 0.10974058450329653\n",
            "\n",
            "Iteration: 50/1000\n",
            "Cost: 0.1096502019667724\n",
            "\n",
            "Iteration: 51/1000\n",
            "Cost: 0.10956369383148053\n",
            "\n",
            "Iteration: 52/1000\n",
            "Cost: 0.10948085133563974\n",
            "\n",
            "Iteration: 53/1000\n",
            "Cost: 0.10940147958815231\n",
            "\n",
            "Iteration: 54/1000\n",
            "Cost: 0.10932539645690308\n",
            "\n",
            "Iteration: 55/1000\n",
            "Cost: 0.10925243156241832\n",
            "\n",
            "Iteration: 56/1000\n",
            "Cost: 0.10918242536525696\n",
            "\n",
            "Iteration: 57/1000\n",
            "Cost: 0.10911522833698313\n",
            "\n",
            "Iteration: 58/1000\n",
            "Cost: 0.1090507002058321\n",
            "\n",
            "Iteration: 59/1000\n",
            "Cost: 0.10898870926926653\n",
            "\n",
            "Iteration: 60/1000\n",
            "Cost: 0.10892913176655308\n",
            "\n",
            "Iteration: 61/1000\n",
            "Cost: 0.10887185130529765\n",
            "\n",
            "Iteration: 62/1000\n",
            "Cost: 0.10881675833657643\n",
            "\n",
            "Iteration: 63/1000\n",
            "Cost: 0.10876374967390942\n",
            "\n",
            "Iteration: 64/1000\n",
            "Cost: 0.10871272805185155\n",
            "\n",
            "Iteration: 65/1000\n",
            "Cost: 0.10866360172044265\n",
            "\n",
            "Iteration: 66/1000\n",
            "Cost: 0.10861628407216083\n",
            "\n",
            "Iteration: 67/1000\n",
            "Cost: 0.10857069329838297\n",
            "\n",
            "Iteration: 68/1000\n",
            "Cost: 0.10852675207266851\n",
            "\n",
            "Iteration: 69/1000\n",
            "Cost: 0.10848438725845999\n",
            "\n",
            "Iteration: 70/1000\n",
            "Cost: 0.10844352963903928\n",
            "\n",
            "Iteration: 71/1000\n",
            "Cost: 0.10840411366779423\n",
            "\n",
            "Iteration: 72/1000\n",
            "Cost: 0.10836607723704418\n",
            "\n",
            "Iteration: 73/1000\n",
            "Cost: 0.10832936146384263\n",
            "\n",
            "Iteration: 74/1000\n",
            "Cost: 0.10829391049132854\n",
            "\n",
            "Iteration: 75/1000\n",
            "Cost: 0.10825967130433346\n",
            "\n",
            "Iteration: 76/1000\n",
            "Cost: 0.10822659355807308\n",
            "\n",
            "Iteration: 77/1000\n",
            "Cost: 0.10819462941886011\n",
            "\n",
            "Iteration: 78/1000\n",
            "Cost: 0.10816373341587417\n",
            "\n",
            "Iteration: 79/1000\n",
            "Cost: 0.10813386230310987\n",
            "\n",
            "Iteration: 80/1000\n",
            "Cost: 0.10810497493070415\n",
            "\n",
            "Iteration: 81/1000\n",
            "Cost: 0.10807703212491514\n",
            "\n",
            "Iteration: 82/1000\n",
            "Cost: 0.10804999657608638\n",
            "\n",
            "Iteration: 83/1000\n",
            "Cost: 0.10802383273399073\n",
            "\n",
            "Iteration: 84/1000\n",
            "Cost: 0.10799850670999765\n",
            "\n",
            "Iteration: 85/1000\n",
            "Cost: 0.10797398618555643\n",
            "\n",
            "Iteration: 86/1000\n",
            "Cost: 0.10795024032652942\n",
            "\n",
            "Iteration: 87/1000\n",
            "Cost: 0.10792723970294839\n",
            "\n",
            "Iteration: 88/1000\n",
            "Cost: 0.1079049562138023\n",
            "\n",
            "Iteration: 89/1000\n",
            "Cost: 0.10788336301649615\n",
            "\n",
            "Iteration: 90/1000\n",
            "Cost: 0.10786243446065046\n",
            "\n",
            "Iteration: 91/1000\n",
            "Cost: 0.10784214602593548\n",
            "\n",
            "Iteration: 92/1000\n",
            "Cost: 0.10782247426366122\n",
            "\n",
            "Iteration: 93/1000\n",
            "Cost: 0.10780339674186322\n",
            "\n",
            "Iteration: 94/1000\n",
            "Cost: 0.10778489199364574\n",
            "\n",
            "Iteration: 95/1000\n",
            "Cost: 0.1077669394685626\n",
            "\n",
            "Iteration: 96/1000\n",
            "Cost: 0.10774951948683138\n",
            "\n",
            "Iteration: 97/1000\n",
            "Cost: 0.10773261319619301\n",
            "\n",
            "Iteration: 98/1000\n",
            "Cost: 0.10771620253124231\n",
            "\n",
            "Iteration: 99/1000\n",
            "Cost: 0.10770027017506881\n",
            "\n",
            "Iteration: 100/1000\n",
            "Cost: 0.10768479952305761\n",
            "\n",
            "Iteration: 101/1000\n",
            "Cost: 0.10766977464871168\n",
            "\n",
            "Iteration: 102/1000\n",
            "Cost: 0.107655180271368\n",
            "\n",
            "Iteration: 103/1000\n",
            "Cost: 0.10764100172568644\n",
            "\n",
            "Iteration: 104/1000\n",
            "Cost: 0.10762722493280194\n",
            "\n",
            "Iteration: 105/1000\n",
            "Cost: 0.10761383637303598\n",
            "\n",
            "Iteration: 106/1000\n",
            "Cost: 0.10760082306007147\n",
            "\n",
            "Iteration: 107/1000\n",
            "Cost: 0.1075881725165019\n",
            "\n",
            "Iteration: 108/1000\n",
            "Cost: 0.10757587275067124\n",
            "\n",
            "Iteration: 109/1000\n",
            "Cost: 0.10756391223472742\n",
            "\n",
            "Iteration: 110/1000\n",
            "Cost: 0.10755227988381674\n",
            "\n",
            "Iteration: 111/1000\n",
            "Cost: 0.1075409650363518\n",
            "\n",
            "Iteration: 112/1000\n",
            "Cost: 0.10752995743528967\n",
            "\n",
            "Iteration: 113/1000\n",
            "Cost: 0.10751924721036246\n",
            "\n",
            "Iteration: 114/1000\n",
            "Cost: 0.10750882486120356\n",
            "\n",
            "Iteration: 115/1000\n",
            "Cost: 0.10749868124132017\n",
            "\n",
            "Iteration: 116/1000\n",
            "Cost: 0.10748880754286182\n",
            "\n",
            "Iteration: 117/1000\n",
            "Cost: 0.10747919528214188\n",
            "\n",
            "Iteration: 118/1000\n",
            "Cost: 0.10746983628586827\n",
            "\n",
            "Iteration: 119/1000\n",
            "Cost: 0.10746072267804503\n",
            "\n",
            "Iteration: 120/1000\n",
            "Cost: 0.10745184686750647\n",
            "\n",
            "Iteration: 121/1000\n",
            "Cost: 0.10744320153605073\n",
            "\n",
            "Iteration: 122/1000\n",
            "Cost: 0.10743477962713807\n",
            "\n",
            "Iteration: 123/1000\n",
            "Cost: 0.10742657433512544\n",
            "\n",
            "Iteration: 124/1000\n",
            "Cost: 0.10741857909500716\n",
            "\n",
            "Iteration: 125/1000\n",
            "Cost: 0.10741078757263481\n",
            "\n",
            "Iteration: 126/1000\n",
            "Cost: 0.10740319365539142\n",
            "\n",
            "Iteration: 127/1000\n",
            "Cost: 0.10739579144329582\n",
            "\n",
            "Iteration: 128/1000\n",
            "Cost: 0.10738857524051466\n",
            "\n",
            "Iteration: 129/1000\n",
            "Cost: 0.10738153954726073\n",
            "\n",
            "Iteration: 130/1000\n",
            "Cost: 0.10737467905205794\n",
            "\n",
            "Iteration: 131/1000\n",
            "Cost: 0.1073679886243542\n",
            "\n",
            "Iteration: 132/1000\n",
            "Cost: 0.10736146330746406\n",
            "\n",
            "Iteration: 133/1000\n",
            "Cost: 0.10735509831182516\n",
            "\n",
            "Iteration: 134/1000\n",
            "Cost: 0.10734888900855183\n",
            "\n",
            "Iteration: 135/1000\n",
            "Cost: 0.10734283092327186\n",
            "\n",
            "Iteration: 136/1000\n",
            "Cost: 0.10733691973023177\n",
            "\n",
            "Iteration: 137/1000\n",
            "Cost: 0.10733115124665762\n",
            "\n",
            "Iteration: 138/1000\n",
            "Cost: 0.107325521427359\n",
            "\n",
            "Iteration: 139/1000\n",
            "Cost: 0.10732002635956386\n",
            "\n",
            "Iteration: 140/1000\n",
            "Cost: 0.10731466225797372\n",
            "\n",
            "Iteration: 141/1000\n",
            "Cost: 0.10730942546002742\n",
            "\n",
            "Iteration: 142/1000\n",
            "Cost: 0.10730431242136582\n",
            "\n",
            "Iteration: 143/1000\n",
            "Cost: 0.10729931971148486\n",
            "\n",
            "Iteration: 144/1000\n",
            "Cost: 0.10729444400957013\n",
            "\n",
            "Iteration: 145/1000\n",
            "Cost: 0.10728968210050437\n",
            "\n",
            "Iteration: 146/1000\n",
            "Cost: 0.10728503087103877\n",
            "\n",
            "Iteration: 147/1000\n",
            "Cost: 0.10728048730612118\n",
            "\n",
            "Iteration: 148/1000\n",
            "Cost: 0.10727604848537432\n",
            "\n",
            "Iteration: 149/1000\n",
            "Cost: 0.10727171157971592\n",
            "\n",
            "Iteration: 150/1000\n",
            "Cost: 0.10726747384811589\n",
            "\n",
            "Iteration: 151/1000\n",
            "Cost: 0.1072633326344828\n",
            "\n",
            "Iteration: 152/1000\n",
            "Cost: 0.10725928536467516\n",
            "\n",
            "Iteration: 153/1000\n",
            "Cost: 0.10725532954363054\n",
            "\n",
            "Iteration: 154/1000\n",
            "Cost: 0.10725146275260895\n",
            "\n",
            "Iteration: 155/1000\n",
            "Cost: 0.10724768264654375\n",
            "\n",
            "Iteration: 156/1000\n",
            "Cost: 0.10724398695149612\n",
            "\n",
            "Iteration: 157/1000\n",
            "Cost: 0.1072403734622092\n",
            "\n",
            "Iteration: 158/1000\n",
            "Cost: 0.10723684003975592\n",
            "\n",
            "Iteration: 159/1000\n",
            "Cost: 0.10723338460927828\n",
            "\n",
            "Iteration: 160/1000\n",
            "Cost: 0.10723000515781266\n",
            "\n",
            "Iteration: 161/1000\n",
            "Cost: 0.1072266997321982\n",
            "\n",
            "Iteration: 162/1000\n",
            "Cost: 0.10722346643706464\n",
            "\n",
            "Iteration: 163/1000\n",
            "Cost: 0.10722030343289643\n",
            "\n",
            "Iteration: 164/1000\n",
            "Cost: 0.10721720893416915\n",
            "\n",
            "Iteration: 165/1000\n",
            "Cost: 0.10721418120755583\n",
            "\n",
            "Iteration: 166/1000\n",
            "Cost: 0.10721121857020026\n",
            "\n",
            "Iteration: 167/1000\n",
            "Cost: 0.10720831938805436\n",
            "\n",
            "Iteration: 168/1000\n",
            "Cost: 0.10720548207427652\n",
            "\n",
            "Iteration: 169/1000\n",
            "Cost: 0.10720270508768946\n",
            "\n",
            "Iteration: 170/1000\n",
            "Cost: 0.1071999869312936\n",
            "\n",
            "Iteration: 171/1000\n",
            "Cost: 0.10719732615083581\n",
            "\n",
            "Iteration: 172/1000\n",
            "Cost: 0.10719472133342901\n",
            "\n",
            "Iteration: 173/1000\n",
            "Cost: 0.10719217110622199\n",
            "\n",
            "Iteration: 174/1000\n",
            "Cost: 0.10718967413511718\n",
            "\n",
            "Iteration: 175/1000\n",
            "Cost: 0.10718722912353443\n",
            "\n",
            "Iteration: 176/1000\n",
            "Cost: 0.10718483481121843\n",
            "\n",
            "Iteration: 177/1000\n",
            "Cost: 0.10718248997308881\n",
            "\n",
            "Iteration: 178/1000\n",
            "Cost: 0.10718019341813093\n",
            "\n",
            "Iteration: 179/1000\n",
            "Cost: 0.1071779439883254\n",
            "\n",
            "Iteration: 180/1000\n",
            "Cost: 0.1071757405576157\n",
            "\n",
            "Iteration: 181/1000\n",
            "Cost: 0.1071735820309112\n",
            "\n",
            "Iteration: 182/1000\n",
            "Cost: 0.10717146734312555\n",
            "\n",
            "Iteration: 183/1000\n",
            "Cost: 0.10716939545824762\n",
            "\n",
            "Iteration: 184/1000\n",
            "Cost: 0.1071673653684455\n",
            "\n",
            "Iteration: 185/1000\n",
            "Cost: 0.10716537609320002\n",
            "\n",
            "Iteration: 186/1000\n",
            "Cost: 0.10716342667846938\n",
            "\n",
            "Iteration: 187/1000\n",
            "Cost: 0.10716151619588106\n",
            "\n",
            "Iteration: 188/1000\n",
            "Cost: 0.107159643741952\n",
            "\n",
            "Iteration: 189/1000\n",
            "Cost: 0.10715780843733455\n",
            "\n",
            "Iteration: 190/1000\n",
            "Cost: 0.10715600942608863\n",
            "\n",
            "Iteration: 191/1000\n",
            "Cost: 0.10715424587497753\n",
            "\n",
            "Iteration: 192/1000\n",
            "Cost: 0.10715251697278762\n",
            "\n",
            "Iteration: 193/1000\n",
            "Cost: 0.10715082192967113\n",
            "\n",
            "Iteration: 194/1000\n",
            "Cost: 0.10714915997651019\n",
            "\n",
            "Iteration: 195/1000\n",
            "Cost: 0.10714753036430208\n",
            "\n",
            "Iteration: 196/1000\n",
            "Cost: 0.10714593236356511\n",
            "\n",
            "Iteration: 197/1000\n",
            "Cost: 0.10714436526376346\n",
            "\n",
            "Iteration: 198/1000\n",
            "Cost: 0.10714282837275145\n",
            "\n",
            "Iteration: 199/1000\n",
            "Cost: 0.10714132101623532\n",
            "\n",
            "Iteration: 200/1000\n",
            "Cost: 0.10713984253725331\n",
            "\n",
            "Iteration: 201/1000\n",
            "Cost: 0.10713839229567168\n",
            "\n",
            "Iteration: 202/1000\n",
            "Cost: 0.10713696966769784\n",
            "\n",
            "Iteration: 203/1000\n",
            "Cost: 0.10713557404540851\n",
            "\n",
            "Iteration: 204/1000\n",
            "Cost: 0.10713420483629361\n",
            "\n",
            "Iteration: 205/1000\n",
            "Cost: 0.10713286146281405\n",
            "\n",
            "Iteration: 206/1000\n",
            "Cost: 0.1071315433619742\n",
            "\n",
            "Iteration: 207/1000\n",
            "Cost: 0.10713024998490771\n",
            "\n",
            "Iteration: 208/1000\n",
            "Cost: 0.10712898079647641\n",
            "\n",
            "Iteration: 209/1000\n",
            "Cost: 0.10712773527488167\n",
            "\n",
            "Iteration: 210/1000\n",
            "Cost: 0.10712651291128869\n",
            "\n",
            "Iteration: 211/1000\n",
            "Cost: 0.1071253132094617\n",
            "\n",
            "Iteration: 212/1000\n",
            "Cost: 0.10712413568541107\n",
            "\n",
            "Iteration: 213/1000\n",
            "Cost: 0.10712297986705122\n",
            "\n",
            "Iteration: 214/1000\n",
            "Cost: 0.10712184529386924\n",
            "\n",
            "Iteration: 215/1000\n",
            "Cost: 0.10712073151660377\n",
            "\n",
            "Iteration: 216/1000\n",
            "Cost: 0.1071196380969337\n",
            "\n",
            "Iteration: 217/1000\n",
            "Cost: 0.1071185646071764\n",
            "\n",
            "Iteration: 218/1000\n",
            "Cost: 0.10711751062999542\n",
            "\n",
            "Iteration: 219/1000\n",
            "Cost: 0.10711647575811693\n",
            "\n",
            "Iteration: 220/1000\n",
            "Cost: 0.10711545959405479\n",
            "\n",
            "Iteration: 221/1000\n",
            "Cost: 0.10711446174984403\n",
            "\n",
            "Iteration: 222/1000\n",
            "Cost: 0.10711348184678249\n",
            "\n",
            "Iteration: 223/1000\n",
            "Cost: 0.10711251951517999\n",
            "\n",
            "Iteration: 224/1000\n",
            "Cost: 0.10711157439411532\n",
            "\n",
            "Iteration: 225/1000\n",
            "Cost: 0.10711064613120048\n",
            "\n",
            "Iteration: 226/1000\n",
            "Cost: 0.10710973438235175\n",
            "\n",
            "Iteration: 227/1000\n",
            "Cost: 0.1071088388115678\n",
            "\n",
            "Iteration: 228/1000\n",
            "Cost: 0.10710795909071431\n",
            "\n",
            "Iteration: 229/1000\n",
            "Cost: 0.10710709489931491\n",
            "\n",
            "Iteration: 230/1000\n",
            "Cost: 0.10710624592434864\n",
            "\n",
            "Iteration: 231/1000\n",
            "Cost: 0.10710541186005287\n",
            "\n",
            "Iteration: 232/1000\n",
            "Cost: 0.10710459240773224\n",
            "\n",
            "Iteration: 233/1000\n",
            "Cost: 0.10710378727557349\n",
            "\n",
            "Iteration: 234/1000\n",
            "Cost: 0.10710299617846493\n",
            "\n",
            "Iteration: 235/1000\n",
            "Cost: 0.10710221883782223\n",
            "\n",
            "Iteration: 236/1000\n",
            "Cost: 0.10710145498141815\n",
            "\n",
            "Iteration: 237/1000\n",
            "Cost: 0.10710070434321821\n",
            "\n",
            "Iteration: 238/1000\n",
            "Cost: 0.10709996666322029\n",
            "\n",
            "Iteration: 239/1000\n",
            "Cost: 0.10709924168729924\n",
            "\n",
            "Iteration: 240/1000\n",
            "Cost: 0.107098529167056\n",
            "\n",
            "Iteration: 241/1000\n",
            "Cost: 0.10709782885967087\n",
            "\n",
            "Iteration: 242/1000\n",
            "Cost: 0.1070971405277613\n",
            "\n",
            "Iteration: 243/1000\n",
            "Cost: 0.10709646393924274\n",
            "\n",
            "Iteration: 244/1000\n",
            "Cost: 0.10709579886719506\n",
            "\n",
            "Iteration: 245/1000\n",
            "Cost: 0.10709514508973114\n",
            "\n",
            "Iteration: 246/1000\n",
            "Cost: 0.10709450238987027\n",
            "\n",
            "Iteration: 247/1000\n",
            "Cost: 0.1070938705554146\n",
            "\n",
            "Iteration: 248/1000\n",
            "Cost: 0.10709324937882907\n",
            "\n",
            "Iteration: 249/1000\n",
            "Cost: 0.10709263865712491\n",
            "\n",
            "Iteration: 250/1000\n",
            "Cost: 0.10709203819174636\n",
            "\n",
            "Iteration: 251/1000\n",
            "Cost: 0.10709144778846034\n",
            "\n",
            "Iteration: 252/1000\n",
            "Cost: 0.1070908672572492\n",
            "\n",
            "Iteration: 253/1000\n",
            "Cost: 0.107090296412207\n",
            "\n",
            "Iteration: 254/1000\n",
            "Cost: 0.10708973507143742\n",
            "\n",
            "Iteration: 255/1000\n",
            "Cost: 0.10708918305695607\n",
            "\n",
            "Iteration: 256/1000\n",
            "Cost: 0.10708864019459426\n",
            "\n",
            "Iteration: 257/1000\n",
            "Cost: 0.10708810631390572\n",
            "\n",
            "Iteration: 258/1000\n",
            "Cost: 0.10708758124807628\n",
            "\n",
            "Iteration: 259/1000\n",
            "Cost: 0.10708706483383523\n",
            "\n",
            "Iteration: 260/1000\n",
            "Cost: 0.10708655691136999\n",
            "\n",
            "Iteration: 261/1000\n",
            "Cost: 0.1070860573242427\n",
            "\n",
            "Iteration: 262/1000\n",
            "Cost: 0.10708556591930819\n",
            "\n",
            "Iteration: 263/1000\n",
            "Cost: 0.10708508254663605\n",
            "\n",
            "Iteration: 264/1000\n",
            "Cost: 0.10708460705943312\n",
            "\n",
            "Iteration: 265/1000\n",
            "Cost: 0.10708413931396853\n",
            "\n",
            "Iteration: 266/1000\n",
            "Cost: 0.10708367916950122\n",
            "\n",
            "Iteration: 267/1000\n",
            "Cost: 0.10708322648820903\n",
            "\n",
            "Iteration: 268/1000\n",
            "Cost: 0.10708278113511938\n",
            "\n",
            "Iteration: 269/1000\n",
            "Cost: 0.10708234297804217\n",
            "\n",
            "Iteration: 270/1000\n",
            "Cost: 0.10708191188750464\n",
            "\n",
            "Iteration: 271/1000\n",
            "Cost: 0.1070814877366873\n",
            "\n",
            "Iteration: 272/1000\n",
            "Cost: 0.10708107040136236\n",
            "\n",
            "Iteration: 273/1000\n",
            "Cost: 0.10708065975983269\n",
            "\n",
            "Iteration: 274/1000\n",
            "Cost: 0.10708025569287377\n",
            "\n",
            "Iteration: 275/1000\n",
            "Cost: 0.10707985808367572\n",
            "\n",
            "Iteration: 276/1000\n",
            "Cost: 0.10707946681778814\n",
            "\n",
            "Iteration: 277/1000\n",
            "Cost: 0.1070790817830652\n",
            "\n",
            "Iteration: 278/1000\n",
            "Cost: 0.107078702869613\n",
            "\n",
            "Iteration: 279/1000\n",
            "Cost: 0.10707832996973811\n",
            "\n",
            "Iteration: 280/1000\n",
            "Cost: 0.10707796297789691\n",
            "\n",
            "Iteration: 281/1000\n",
            "Cost: 0.10707760179064708\n",
            "\n",
            "Iteration: 282/1000\n",
            "Cost: 0.10707724630659972\n",
            "\n",
            "Iteration: 283/1000\n",
            "Cost: 0.10707689642637284\n",
            "\n",
            "Iteration: 284/1000\n",
            "Cost: 0.10707655205254601\n",
            "\n",
            "Iteration: 285/1000\n",
            "Cost: 0.10707621308961625\n",
            "\n",
            "Iteration: 286/1000\n",
            "Cost: 0.10707587944395527\n",
            "\n",
            "Iteration: 287/1000\n",
            "Cost: 0.10707555102376695\n",
            "\n",
            "Iteration: 288/1000\n",
            "Cost: 0.107075227739047\n",
            "\n",
            "Iteration: 289/1000\n",
            "Cost: 0.1070749095015429\n",
            "\n",
            "Iteration: 290/1000\n",
            "Cost: 0.10707459622471466\n",
            "\n",
            "Iteration: 291/1000\n",
            "Cost: 0.10707428782369774\n",
            "\n",
            "Iteration: 292/1000\n",
            "Cost: 0.10707398421526552\n",
            "\n",
            "Iteration: 293/1000\n",
            "Cost: 0.1070736853177931\n",
            "\n",
            "Iteration: 294/1000\n",
            "Cost: 0.10707339105122295\n",
            "\n",
            "Iteration: 295/1000\n",
            "Cost: 0.10707310133702962\n",
            "\n",
            "Iteration: 296/1000\n",
            "Cost: 0.10707281609818724\n",
            "\n",
            "Iteration: 297/1000\n",
            "Cost: 0.10707253525913626\n",
            "\n",
            "Iteration: 298/1000\n",
            "Cost: 0.10707225874575213\n",
            "\n",
            "Iteration: 299/1000\n",
            "Cost: 0.1070719864853141\n",
            "\n",
            "Iteration: 300/1000\n",
            "Cost: 0.10707171840647454\n",
            "\n",
            "Iteration: 301/1000\n",
            "Cost: 0.10707145443923027\n",
            "\n",
            "Iteration: 302/1000\n",
            "Cost: 0.10707119451489282\n",
            "\n",
            "Iteration: 303/1000\n",
            "Cost: 0.10707093856606095\n",
            "\n",
            "Iteration: 304/1000\n",
            "Cost: 0.10707068652659325\n",
            "\n",
            "Iteration: 305/1000\n",
            "Cost: 0.10707043833158082\n",
            "\n",
            "Iteration: 306/1000\n",
            "Cost: 0.10707019391732141\n",
            "\n",
            "Iteration: 307/1000\n",
            "Cost: 0.1070699532212944\n",
            "\n",
            "Iteration: 308/1000\n",
            "Cost: 0.10706971618213484\n",
            "\n",
            "Iteration: 309/1000\n",
            "Cost: 0.10706948273961019\n",
            "\n",
            "Iteration: 310/1000\n",
            "Cost: 0.10706925283459613\n",
            "\n",
            "Iteration: 311/1000\n",
            "Cost: 0.10706902640905326\n",
            "\n",
            "Iteration: 312/1000\n",
            "Cost: 0.10706880340600478\n",
            "\n",
            "Iteration: 313/1000\n",
            "Cost: 0.10706858376951421\n",
            "\n",
            "Iteration: 314/1000\n",
            "Cost: 0.10706836744466415\n",
            "\n",
            "Iteration: 315/1000\n",
            "Cost: 0.10706815437753443\n",
            "\n",
            "Iteration: 316/1000\n",
            "Cost: 0.10706794451518256\n",
            "\n",
            "Iteration: 317/1000\n",
            "Cost: 0.10706773780562304\n",
            "\n",
            "Iteration: 318/1000\n",
            "Cost: 0.10706753419780779\n",
            "\n",
            "Iteration: 319/1000\n",
            "Cost: 0.10706733364160707\n",
            "\n",
            "Iteration: 320/1000\n",
            "Cost: 0.10706713608779075\n",
            "\n",
            "Iteration: 321/1000\n",
            "Cost: 0.10706694148801016\n",
            "\n",
            "Iteration: 322/1000\n",
            "Cost: 0.10706674979477995\n",
            "\n",
            "Iteration: 323/1000\n",
            "Cost: 0.10706656096146067\n",
            "\n",
            "Iteration: 324/1000\n",
            "Cost: 0.10706637494224197\n",
            "\n",
            "Iteration: 325/1000\n",
            "Cost: 0.10706619169212578\n",
            "\n",
            "Iteration: 326/1000\n",
            "Cost: 0.1070660111669099\n",
            "\n",
            "Iteration: 327/1000\n",
            "Cost: 0.10706583332317213\n",
            "\n",
            "Iteration: 328/1000\n",
            "Cost: 0.10706565811825498\n",
            "\n",
            "Iteration: 329/1000\n",
            "Cost: 0.10706548551025014\n",
            "\n",
            "Iteration: 330/1000\n",
            "Cost: 0.1070653154579837\n",
            "\n",
            "Iteration: 331/1000\n",
            "Cost: 0.1070651479210017\n",
            "\n",
            "Iteration: 332/1000\n",
            "Cost: 0.1070649828595558\n",
            "\n",
            "Iteration: 333/1000\n",
            "Cost: 0.10706482023458963\n",
            "\n",
            "Iteration: 334/1000\n",
            "Cost: 0.1070646600077249\n",
            "\n",
            "Iteration: 335/1000\n",
            "Cost: 0.10706450214124821\n",
            "\n",
            "Iteration: 336/1000\n",
            "Cost: 0.10706434659809833\n",
            "\n",
            "Iteration: 337/1000\n",
            "Cost: 0.10706419334185317\n",
            "\n",
            "Iteration: 338/1000\n",
            "Cost: 0.10706404233671762\n",
            "\n",
            "Iteration: 339/1000\n",
            "Cost: 0.10706389354751122\n",
            "\n",
            "Iteration: 340/1000\n",
            "Cost: 0.10706374693965628\n",
            "\n",
            "Iteration: 341/1000\n",
            "Cost: 0.10706360247916652\n",
            "\n",
            "Iteration: 342/1000\n",
            "Cost: 0.10706346013263544\n",
            "\n",
            "Iteration: 343/1000\n",
            "Cost: 0.10706331986722517\n",
            "\n",
            "Iteration: 344/1000\n",
            "Cost: 0.10706318165065598\n",
            "\n",
            "Iteration: 345/1000\n",
            "Cost: 0.10706304545119513\n",
            "\n",
            "Iteration: 346/1000\n",
            "Cost: 0.10706291123764705\n",
            "\n",
            "Iteration: 347/1000\n",
            "Cost: 0.1070627789793424\n",
            "\n",
            "Iteration: 348/1000\n",
            "Cost: 0.10706264864612895\n",
            "\n",
            "Iteration: 349/1000\n",
            "Cost: 0.1070625202083612\n",
            "\n",
            "Iteration: 350/1000\n",
            "Cost: 0.10706239363689098\n",
            "\n",
            "Iteration: 351/1000\n",
            "Cost: 0.10706226890305838\n",
            "\n",
            "Iteration: 352/1000\n",
            "Cost: 0.10706214597868206\n",
            "\n",
            "Iteration: 353/1000\n",
            "Cost: 0.1070620248360512\n",
            "\n",
            "Iteration: 354/1000\n",
            "Cost: 0.10706190544791568\n",
            "\n",
            "Iteration: 355/1000\n",
            "Cost: 0.10706178778747837\n",
            "\n",
            "Iteration: 356/1000\n",
            "Cost: 0.10706167182838602\n",
            "\n",
            "Iteration: 357/1000\n",
            "Cost: 0.10706155754472185\n",
            "\n",
            "Iteration: 358/1000\n",
            "Cost: 0.10706144491099662\n",
            "\n",
            "Iteration: 359/1000\n",
            "Cost: 0.10706133390214154\n",
            "\n",
            "Iteration: 360/1000\n",
            "Cost: 0.1070612244935001\n",
            "\n",
            "Iteration: 361/1000\n",
            "Cost: 0.10706111666082047\n",
            "\n",
            "Iteration: 362/1000\n",
            "Cost: 0.10706101038024869\n",
            "\n",
            "Iteration: 363/1000\n",
            "Cost: 0.10706090562832038\n",
            "\n",
            "Iteration: 364/1000\n",
            "Cost: 0.10706080238195483\n",
            "\n",
            "Iteration: 365/1000\n",
            "Cost: 0.10706070061844711\n",
            "\n",
            "Iteration: 366/1000\n",
            "Cost: 0.10706060031546177\n",
            "\n",
            "Iteration: 367/1000\n",
            "Cost: 0.10706050145102611\n",
            "\n",
            "Iteration: 368/1000\n",
            "Cost: 0.1070604040035235\n",
            "\n",
            "Iteration: 369/1000\n",
            "Cost: 0.10706030795168706\n",
            "\n",
            "Iteration: 370/1000\n",
            "Cost: 0.10706021327459321\n",
            "\n",
            "Iteration: 371/1000\n",
            "Cost: 0.10706011995165612\n",
            "\n",
            "Iteration: 372/1000\n",
            "Cost: 0.1070600279626209\n",
            "\n",
            "Iteration: 373/1000\n",
            "Cost: 0.10705993728755826\n",
            "\n",
            "Iteration: 374/1000\n",
            "Cost: 0.10705984790685856\n",
            "\n",
            "Iteration: 375/1000\n",
            "Cost: 0.10705975980122592\n",
            "\n",
            "Iteration: 376/1000\n",
            "Cost: 0.10705967295167322\n",
            "\n",
            "Iteration: 377/1000\n",
            "Cost: 0.10705958733951594\n",
            "\n",
            "Iteration: 378/1000\n",
            "Cost: 0.10705950294636755\n",
            "\n",
            "Iteration: 379/1000\n",
            "Cost: 0.10705941975413365\n",
            "\n",
            "Iteration: 380/1000\n",
            "Cost: 0.10705933774500745\n",
            "\n",
            "Iteration: 381/1000\n",
            "Cost: 0.10705925690146423\n",
            "\n",
            "Iteration: 382/1000\n",
            "Cost: 0.10705917720625656\n",
            "\n",
            "Iteration: 383/1000\n",
            "Cost: 0.10705909864240977\n",
            "\n",
            "Iteration: 384/1000\n",
            "Cost: 0.10705902119321692\n",
            "\n",
            "Iteration: 385/1000\n",
            "Cost: 0.10705894484223398\n",
            "\n",
            "Iteration: 386/1000\n",
            "Cost: 0.10705886957327569\n",
            "\n",
            "Iteration: 387/1000\n",
            "Cost: 0.10705879537041119\n",
            "\n",
            "Iteration: 388/1000\n",
            "Cost: 0.10705872221795885\n",
            "\n",
            "Iteration: 389/1000\n",
            "Cost: 0.10705865010048302\n",
            "\n",
            "Iteration: 390/1000\n",
            "Cost: 0.10705857900278898\n",
            "\n",
            "Iteration: 391/1000\n",
            "Cost: 0.10705850890991925\n",
            "\n",
            "Iteration: 392/1000\n",
            "Cost: 0.1070584398071496\n",
            "\n",
            "Iteration: 393/1000\n",
            "Cost: 0.10705837167998458\n",
            "\n",
            "Iteration: 394/1000\n",
            "Cost: 0.10705830451415432\n",
            "\n",
            "Iteration: 395/1000\n",
            "Cost: 0.10705823829561012\n",
            "\n",
            "Iteration: 396/1000\n",
            "Cost: 0.10705817301052108\n",
            "\n",
            "Iteration: 397/1000\n",
            "Cost: 0.1070581086452699\n",
            "\n",
            "Iteration: 398/1000\n",
            "Cost: 0.10705804518645036\n",
            "\n",
            "Iteration: 399/1000\n",
            "Cost: 0.10705798262086233\n",
            "\n",
            "Iteration: 400/1000\n",
            "Cost: 0.10705792093550957\n",
            "\n",
            "Iteration: 401/1000\n",
            "Cost: 0.10705786011759538\n",
            "\n",
            "Iteration: 402/1000\n",
            "Cost: 0.10705780015452002\n",
            "\n",
            "Iteration: 403/1000\n",
            "Cost: 0.1070577410338767\n",
            "\n",
            "Iteration: 404/1000\n",
            "Cost: 0.10705768274344916\n",
            "\n",
            "Iteration: 405/1000\n",
            "Cost: 0.10705762527120778\n",
            "\n",
            "Iteration: 406/1000\n",
            "Cost: 0.10705756860530653\n",
            "\n",
            "Iteration: 407/1000\n",
            "Cost: 0.10705751273408087\n",
            "\n",
            "Iteration: 408/1000\n",
            "Cost: 0.1070574576460434\n",
            "\n",
            "Iteration: 409/1000\n",
            "Cost: 0.10705740332988199\n",
            "\n",
            "Iteration: 410/1000\n",
            "Cost: 0.10705734977445625\n",
            "\n",
            "Iteration: 411/1000\n",
            "Cost: 0.10705729696879487\n",
            "\n",
            "Iteration: 412/1000\n",
            "Cost: 0.10705724490209334\n",
            "\n",
            "Iteration: 413/1000\n",
            "Cost: 0.1070571935637103\n",
            "\n",
            "Iteration: 414/1000\n",
            "Cost: 0.10705714294316566\n",
            "\n",
            "Iteration: 415/1000\n",
            "Cost: 0.10705709303013776\n",
            "\n",
            "Iteration: 416/1000\n",
            "Cost: 0.10705704381446038\n",
            "\n",
            "Iteration: 417/1000\n",
            "Cost: 0.10705699528612077\n",
            "\n",
            "Iteration: 418/1000\n",
            "Cost: 0.10705694743525676\n",
            "\n",
            "Iteration: 419/1000\n",
            "Cost: 0.10705690025215472\n",
            "\n",
            "Iteration: 420/1000\n",
            "Cost: 0.10705685372724683\n",
            "\n",
            "Iteration: 421/1000\n",
            "Cost: 0.10705680785110852\n",
            "\n",
            "Iteration: 422/1000\n",
            "Cost: 0.10705676261445693\n",
            "\n",
            "Iteration: 423/1000\n",
            "Cost: 0.10705671800814788\n",
            "\n",
            "Iteration: 424/1000\n",
            "Cost: 0.10705667402317393\n",
            "\n",
            "Iteration: 425/1000\n",
            "Cost: 0.10705663065066212\n",
            "\n",
            "Iteration: 426/1000\n",
            "Cost: 0.10705658788187213\n",
            "\n",
            "Iteration: 427/1000\n",
            "Cost: 0.10705654570819358\n",
            "\n",
            "Iteration: 428/1000\n",
            "Cost: 0.10705650412114451\n",
            "\n",
            "Iteration: 429/1000\n",
            "Cost: 0.1070564631123689\n",
            "\n",
            "Iteration: 430/1000\n",
            "Cost: 0.10705642267363497\n",
            "\n",
            "Iteration: 431/1000\n",
            "Cost: 0.10705638279683316\n",
            "\n",
            "Iteration: 432/1000\n",
            "Cost: 0.10705634347397407\n",
            "\n",
            "Iteration: 433/1000\n",
            "Cost: 0.10705630469718651\n",
            "\n",
            "Iteration: 434/1000\n",
            "Cost: 0.10705626645871594\n",
            "\n",
            "Iteration: 435/1000\n",
            "Cost: 0.10705622875092234\n",
            "\n",
            "Iteration: 436/1000\n",
            "Cost: 0.10705619156627832\n",
            "\n",
            "Iteration: 437/1000\n",
            "Cost: 0.10705615489736786\n",
            "\n",
            "Iteration: 438/1000\n",
            "Cost: 0.10705611873688392\n",
            "\n",
            "Iteration: 439/1000\n",
            "Cost: 0.10705608307762726\n",
            "\n",
            "Iteration: 440/1000\n",
            "Cost: 0.1070560479125045\n",
            "\n",
            "Iteration: 441/1000\n",
            "Cost: 0.10705601323452617\n",
            "\n",
            "Iteration: 442/1000\n",
            "Cost: 0.10705597903680579\n",
            "\n",
            "Iteration: 443/1000\n",
            "Cost: 0.1070559453125576\n",
            "\n",
            "Iteration: 444/1000\n",
            "Cost: 0.10705591205509561\n",
            "\n",
            "Iteration: 445/1000\n",
            "Cost: 0.1070558792578314\n",
            "\n",
            "Iteration: 446/1000\n",
            "Cost: 0.10705584691427304\n",
            "\n",
            "Iteration: 447/1000\n",
            "Cost: 0.10705581501802337\n",
            "\n",
            "Iteration: 448/1000\n",
            "Cost: 0.10705578356277878\n",
            "\n",
            "Iteration: 449/1000\n",
            "Cost: 0.1070557525423275\n",
            "\n",
            "Iteration: 450/1000\n",
            "Cost: 0.10705572195054837\n",
            "\n",
            "Iteration: 451/1000\n",
            "Cost: 0.10705569178140929\n",
            "\n",
            "Iteration: 452/1000\n",
            "Cost: 0.10705566202896594\n",
            "\n",
            "Iteration: 453/1000\n",
            "Cost: 0.1070556326873605\n",
            "\n",
            "Iteration: 454/1000\n",
            "Cost: 0.10705560375082027\n",
            "\n",
            "Iteration: 455/1000\n",
            "Cost: 0.10705557521365604\n",
            "\n",
            "Iteration: 456/1000\n",
            "Cost: 0.10705554707026158\n",
            "\n",
            "Iteration: 457/1000\n",
            "Cost: 0.10705551931511131\n",
            "\n",
            "Iteration: 458/1000\n",
            "Cost: 0.10705549194276022\n",
            "\n",
            "Iteration: 459/1000\n",
            "Cost: 0.10705546494784172\n",
            "\n",
            "Iteration: 460/1000\n",
            "Cost: 0.10705543832506706\n",
            "\n",
            "Iteration: 461/1000\n",
            "Cost: 0.1070554120692235\n",
            "\n",
            "Iteration: 462/1000\n",
            "Cost: 0.1070553861751739\n",
            "\n",
            "Iteration: 463/1000\n",
            "Cost: 0.10705536063785512\n",
            "\n",
            "Iteration: 464/1000\n",
            "Cost: 0.10705533545227676\n",
            "\n",
            "Iteration: 465/1000\n",
            "Cost: 0.10705531061352071\n",
            "\n",
            "Iteration: 466/1000\n",
            "Cost: 0.10705528611673927\n",
            "\n",
            "Iteration: 467/1000\n",
            "Cost: 0.10705526195715474\n",
            "\n",
            "Iteration: 468/1000\n",
            "Cost: 0.10705523813005771\n",
            "\n",
            "Iteration: 469/1000\n",
            "Cost: 0.10705521463080662\n",
            "\n",
            "Iteration: 470/1000\n",
            "Cost: 0.10705519145482668\n",
            "\n",
            "Iteration: 471/1000\n",
            "Cost: 0.10705516859760844\n",
            "\n",
            "Iteration: 472/1000\n",
            "Cost: 0.10705514605470706\n",
            "\n",
            "Iteration: 473/1000\n",
            "Cost: 0.10705512382174164\n",
            "\n",
            "Iteration: 474/1000\n",
            "Cost: 0.10705510189439356\n",
            "\n",
            "Iteration: 475/1000\n",
            "Cost: 0.10705508026840618\n",
            "\n",
            "Iteration: 476/1000\n",
            "Cost: 0.10705505893958384\n",
            "\n",
            "Iteration: 477/1000\n",
            "Cost: 0.10705503790379045\n",
            "\n",
            "Iteration: 478/1000\n",
            "Cost: 0.10705501715694932\n",
            "\n",
            "Iteration: 479/1000\n",
            "Cost: 0.10705499669504163\n",
            "\n",
            "Iteration: 480/1000\n",
            "Cost: 0.10705497651410599\n",
            "\n",
            "Iteration: 481/1000\n",
            "Cost: 0.10705495661023733\n",
            "\n",
            "Iteration: 482/1000\n",
            "Cost: 0.1070549369795863\n",
            "\n",
            "Iteration: 483/1000\n",
            "Cost: 0.10705491761835825\n",
            "\n",
            "Iteration: 484/1000\n",
            "Cost: 0.10705489852281247\n",
            "\n",
            "Iteration: 485/1000\n",
            "Cost: 0.10705487968926145\n",
            "\n",
            "Iteration: 486/1000\n",
            "Cost: 0.10705486111407012\n",
            "\n",
            "Iteration: 487/1000\n",
            "Cost: 0.10705484279365476\n",
            "\n",
            "Iteration: 488/1000\n",
            "Cost: 0.10705482472448277\n",
            "\n",
            "Iteration: 489/1000\n",
            "Cost: 0.10705480690307144\n",
            "\n",
            "Iteration: 490/1000\n",
            "Cost: 0.10705478932598754\n",
            "\n",
            "Iteration: 491/1000\n",
            "Cost: 0.10705477198984639\n",
            "\n",
            "Iteration: 492/1000\n",
            "Cost: 0.10705475489131112\n",
            "\n",
            "Iteration: 493/1000\n",
            "Cost: 0.10705473802709226\n",
            "\n",
            "Iteration: 494/1000\n",
            "Cost: 0.10705472139394663\n",
            "\n",
            "Iteration: 495/1000\n",
            "Cost: 0.10705470498867721\n",
            "\n",
            "Iteration: 496/1000\n",
            "Cost: 0.1070546888081318\n",
            "\n",
            "Iteration: 497/1000\n",
            "Cost: 0.10705467284920274\n",
            "\n",
            "Iteration: 498/1000\n",
            "Cost: 0.10705465710882635\n",
            "\n",
            "Iteration: 499/1000\n",
            "Cost: 0.1070546415839821\n",
            "\n",
            "Iteration: 500/1000\n",
            "Cost: 0.10705462627169188\n",
            "\n",
            "Iteration: 501/1000\n",
            "Cost: 0.10705461116901989\n",
            "\n",
            "Iteration: 502/1000\n",
            "Cost: 0.1070545962730713\n",
            "\n",
            "Iteration: 503/1000\n",
            "Cost: 0.10705458158099206\n",
            "\n",
            "Iteration: 504/1000\n",
            "Cost: 0.10705456708996854\n",
            "\n",
            "Iteration: 505/1000\n",
            "Cost: 0.10705455279722645\n",
            "\n",
            "Iteration: 506/1000\n",
            "Cost: 0.10705453870003033\n",
            "\n",
            "Iteration: 507/1000\n",
            "Cost: 0.10705452479568357\n",
            "\n",
            "Iteration: 508/1000\n",
            "Cost: 0.10705451108152698\n",
            "\n",
            "Iteration: 509/1000\n",
            "Cost: 0.10705449755493897\n",
            "\n",
            "Iteration: 510/1000\n",
            "Cost: 0.10705448421333458\n",
            "\n",
            "Iteration: 511/1000\n",
            "Cost: 0.1070544710541651\n",
            "\n",
            "Iteration: 512/1000\n",
            "Cost: 0.10705445807491767\n",
            "\n",
            "Iteration: 513/1000\n",
            "Cost: 0.1070544452731145\n",
            "\n",
            "Iteration: 514/1000\n",
            "Cost: 0.10705443264631243\n",
            "\n",
            "Iteration: 515/1000\n",
            "Cost: 0.10705442019210272\n",
            "\n",
            "Iteration: 516/1000\n",
            "Cost: 0.10705440790811\n",
            "\n",
            "Iteration: 517/1000\n",
            "Cost: 0.10705439579199241\n",
            "\n",
            "Iteration: 518/1000\n",
            "Cost: 0.10705438384144074\n",
            "\n",
            "Iteration: 519/1000\n",
            "Cost: 0.10705437205417788\n",
            "\n",
            "Iteration: 520/1000\n",
            "Cost: 0.10705436042795877\n",
            "\n",
            "Iteration: 521/1000\n",
            "Cost: 0.10705434896056948\n",
            "\n",
            "Iteration: 522/1000\n",
            "Cost: 0.10705433764982715\n",
            "\n",
            "Iteration: 523/1000\n",
            "Cost: 0.10705432649357913\n",
            "\n",
            "Iteration: 524/1000\n",
            "Cost: 0.1070543154897031\n",
            "\n",
            "Iteration: 525/1000\n",
            "Cost: 0.10705430463610606\n",
            "\n",
            "Iteration: 526/1000\n",
            "Cost: 0.10705429393072435\n",
            "\n",
            "Iteration: 527/1000\n",
            "Cost: 0.10705428337152284\n",
            "\n",
            "Iteration: 528/1000\n",
            "Cost: 0.107054272956495\n",
            "\n",
            "Iteration: 529/1000\n",
            "Cost: 0.10705426268366193\n",
            "\n",
            "Iteration: 530/1000\n",
            "Cost: 0.10705425255107251\n",
            "\n",
            "Iteration: 531/1000\n",
            "Cost: 0.10705424255680265\n",
            "\n",
            "Iteration: 532/1000\n",
            "Cost: 0.10705423269895495\n",
            "\n",
            "Iteration: 533/1000\n",
            "Cost: 0.10705422297565846\n",
            "\n",
            "Iteration: 534/1000\n",
            "Cost: 0.10705421338506828\n",
            "\n",
            "Iteration: 535/1000\n",
            "Cost: 0.10705420392536491\n",
            "\n",
            "Iteration: 536/1000\n",
            "Cost: 0.10705419459475446\n",
            "\n",
            "Iteration: 537/1000\n",
            "Cost: 0.1070541853914674\n",
            "\n",
            "Iteration: 538/1000\n",
            "Cost: 0.1070541763137594\n",
            "\n",
            "Iteration: 539/1000\n",
            "Cost: 0.10705416735990977\n",
            "\n",
            "Iteration: 540/1000\n",
            "Cost: 0.10705415852822209\n",
            "\n",
            "Iteration: 541/1000\n",
            "Cost: 0.10705414981702308\n",
            "\n",
            "Iteration: 542/1000\n",
            "Cost: 0.10705414122466282\n",
            "\n",
            "Iteration: 543/1000\n",
            "Cost: 0.10705413274951439\n",
            "\n",
            "Iteration: 544/1000\n",
            "Cost: 0.10705412438997314\n",
            "\n",
            "Iteration: 545/1000\n",
            "Cost: 0.10705411614445676\n",
            "\n",
            "Iteration: 546/1000\n",
            "Cost: 0.10705410801140486\n",
            "\n",
            "Iteration: 547/1000\n",
            "Cost: 0.10705409998927853\n",
            "\n",
            "Iteration: 548/1000\n",
            "Cost: 0.10705409207656025\n",
            "\n",
            "Iteration: 549/1000\n",
            "Cost: 0.10705408427175331\n",
            "\n",
            "Iteration: 550/1000\n",
            "Cost: 0.10705407657338202\n",
            "\n",
            "Iteration: 551/1000\n",
            "Cost: 0.10705406897999073\n",
            "\n",
            "Iteration: 552/1000\n",
            "Cost: 0.10705406149014403\n",
            "\n",
            "Iteration: 553/1000\n",
            "Cost: 0.10705405410242641\n",
            "\n",
            "Iteration: 554/1000\n",
            "Cost: 0.10705404681544183\n",
            "\n",
            "Iteration: 555/1000\n",
            "Cost: 0.10705403962781342\n",
            "\n",
            "Iteration: 556/1000\n",
            "Cost: 0.1070540325381835\n",
            "\n",
            "Iteration: 557/1000\n",
            "Cost: 0.10705402554521294\n",
            "\n",
            "Iteration: 558/1000\n",
            "Cost: 0.10705401864758125\n",
            "\n",
            "Iteration: 559/1000\n",
            "Cost: 0.10705401184398604\n",
            "\n",
            "Iteration: 560/1000\n",
            "Cost: 0.10705400513314278\n",
            "\n",
            "Iteration: 561/1000\n",
            "Cost: 0.10705399851378487\n",
            "\n",
            "Iteration: 562/1000\n",
            "Cost: 0.10705399198466314\n",
            "\n",
            "Iteration: 563/1000\n",
            "Cost: 0.10705398554454523\n",
            "\n",
            "Iteration: 564/1000\n",
            "Cost: 0.10705397919221632\n",
            "\n",
            "Iteration: 565/1000\n",
            "Cost: 0.1070539729264779\n",
            "\n",
            "Iteration: 566/1000\n",
            "Cost: 0.10705396674614803\n",
            "\n",
            "Iteration: 567/1000\n",
            "Cost: 0.10705396065006113\n",
            "\n",
            "Iteration: 568/1000\n",
            "Cost: 0.10705395463706774\n",
            "\n",
            "Iteration: 569/1000\n",
            "Cost: 0.10705394870603402\n",
            "\n",
            "Iteration: 570/1000\n",
            "Cost: 0.10705394285584172\n",
            "\n",
            "Iteration: 571/1000\n",
            "Cost: 0.10705393708538817\n",
            "\n",
            "Iteration: 572/1000\n",
            "Cost: 0.10705393139358559\n",
            "\n",
            "Iteration: 573/1000\n",
            "Cost: 0.1070539257793612\n",
            "\n",
            "Iteration: 574/1000\n",
            "Cost: 0.1070539202416572\n",
            "\n",
            "Iteration: 575/1000\n",
            "Cost: 0.10705391477943013\n",
            "\n",
            "Iteration: 576/1000\n",
            "Cost: 0.10705390939165076\n",
            "\n",
            "Iteration: 577/1000\n",
            "Cost: 0.10705390407730413\n",
            "\n",
            "Iteration: 578/1000\n",
            "Cost: 0.1070538988353893\n",
            "\n",
            "Iteration: 579/1000\n",
            "Cost: 0.10705389366491885\n",
            "\n",
            "Iteration: 580/1000\n",
            "Cost: 0.10705388856491893\n",
            "\n",
            "Iteration: 581/1000\n",
            "Cost: 0.10705388353442936\n",
            "\n",
            "Iteration: 582/1000\n",
            "Cost: 0.10705387857250281\n",
            "\n",
            "Iteration: 583/1000\n",
            "Cost: 0.1070538736782049\n",
            "\n",
            "Iteration: 584/1000\n",
            "Cost: 0.10705386885061424\n",
            "\n",
            "Iteration: 585/1000\n",
            "Cost: 0.10705386408882214\n",
            "\n",
            "Iteration: 586/1000\n",
            "Cost: 0.10705385939193207\n",
            "\n",
            "Iteration: 587/1000\n",
            "Cost: 0.10705385475905989\n",
            "\n",
            "Iteration: 588/1000\n",
            "Cost: 0.10705385018933396\n",
            "\n",
            "Iteration: 589/1000\n",
            "Cost: 0.10705384568189404\n",
            "\n",
            "Iteration: 590/1000\n",
            "Cost: 0.10705384123589193\n",
            "\n",
            "Iteration: 591/1000\n",
            "Cost: 0.1070538368504909\n",
            "\n",
            "Iteration: 592/1000\n",
            "Cost: 0.10705383252486589\n",
            "\n",
            "Iteration: 593/1000\n",
            "Cost: 0.10705382825820299\n",
            "\n",
            "Iteration: 594/1000\n",
            "Cost: 0.10705382404969942\n",
            "\n",
            "Iteration: 595/1000\n",
            "Cost: 0.10705381989856344\n",
            "\n",
            "Iteration: 596/1000\n",
            "Cost: 0.10705381580401403\n",
            "\n",
            "Iteration: 597/1000\n",
            "Cost: 0.107053811765281\n",
            "\n",
            "Iteration: 598/1000\n",
            "Cost: 0.1070538077816047\n",
            "\n",
            "Iteration: 599/1000\n",
            "Cost: 0.1070538038522357\n",
            "\n",
            "Iteration: 600/1000\n",
            "Cost: 0.10705379997643502\n",
            "\n",
            "Iteration: 601/1000\n",
            "Cost: 0.10705379615347352\n",
            "\n",
            "Iteration: 602/1000\n",
            "Cost: 0.10705379238263234\n",
            "\n",
            "Iteration: 603/1000\n",
            "Cost: 0.10705378866320213\n",
            "\n",
            "Iteration: 604/1000\n",
            "Cost: 0.10705378499448344\n",
            "\n",
            "Iteration: 605/1000\n",
            "Cost: 0.10705378137578639\n",
            "\n",
            "Iteration: 606/1000\n",
            "Cost: 0.10705377780643038\n",
            "\n",
            "Iteration: 607/1000\n",
            "Cost: 0.10705377428574422\n",
            "\n",
            "Iteration: 608/1000\n",
            "Cost: 0.10705377081306584\n",
            "\n",
            "Iteration: 609/1000\n",
            "Cost: 0.10705376738774212\n",
            "\n",
            "Iteration: 610/1000\n",
            "Cost: 0.10705376400912904\n",
            "\n",
            "Iteration: 611/1000\n",
            "Cost: 0.10705376067659117\n",
            "\n",
            "Iteration: 612/1000\n",
            "Cost: 0.10705375738950205\n",
            "\n",
            "Iteration: 613/1000\n",
            "Cost: 0.10705375414724334\n",
            "\n",
            "Iteration: 614/1000\n",
            "Cost: 0.10705375094920559\n",
            "\n",
            "Iteration: 615/1000\n",
            "Cost: 0.10705374779478737\n",
            "\n",
            "Iteration: 616/1000\n",
            "Cost: 0.1070537446833954\n",
            "\n",
            "Iteration: 617/1000\n",
            "Cost: 0.10705374161444475\n",
            "\n",
            "Iteration: 618/1000\n",
            "Cost: 0.1070537385873583\n",
            "\n",
            "Iteration: 619/1000\n",
            "Cost: 0.1070537356015668\n",
            "\n",
            "Iteration: 620/1000\n",
            "Cost: 0.10705373265650892\n",
            "\n",
            "Iteration: 621/1000\n",
            "Cost: 0.1070537297516308\n",
            "\n",
            "Iteration: 622/1000\n",
            "Cost: 0.10705372688638605\n",
            "\n",
            "Iteration: 623/1000\n",
            "Cost: 0.10705372406023608\n",
            "\n",
            "Iteration: 624/1000\n",
            "Cost: 0.10705372127264925\n",
            "\n",
            "Iteration: 625/1000\n",
            "Cost: 0.10705371852310136\n",
            "\n",
            "Iteration: 626/1000\n",
            "Cost: 0.10705371581107545\n",
            "\n",
            "Iteration: 627/1000\n",
            "Cost: 0.10705371313606138\n",
            "\n",
            "Iteration: 628/1000\n",
            "Cost: 0.10705371049755608\n",
            "\n",
            "Iteration: 629/1000\n",
            "Cost: 0.10705370789506323\n",
            "\n",
            "Iteration: 630/1000\n",
            "Cost: 0.10705370532809345\n",
            "\n",
            "Iteration: 631/1000\n",
            "Cost: 0.10705370279616389\n",
            "\n",
            "Iteration: 632/1000\n",
            "Cost: 0.10705370029879835\n",
            "\n",
            "Iteration: 633/1000\n",
            "Cost: 0.10705369783552693\n",
            "\n",
            "Iteration: 634/1000\n",
            "Cost: 0.10705369540588644\n",
            "\n",
            "Iteration: 635/1000\n",
            "Cost: 0.10705369300941965\n",
            "\n",
            "Iteration: 636/1000\n",
            "Cost: 0.1070536906456758\n",
            "\n",
            "Iteration: 637/1000\n",
            "Cost: 0.10705368831421026\n",
            "\n",
            "Iteration: 638/1000\n",
            "Cost: 0.10705368601458427\n",
            "\n",
            "Iteration: 639/1000\n",
            "Cost: 0.10705368374636506\n",
            "\n",
            "Iteration: 640/1000\n",
            "Cost: 0.10705368150912604\n",
            "\n",
            "Iteration: 641/1000\n",
            "Cost: 0.10705367930244605\n",
            "\n",
            "Iteration: 642/1000\n",
            "Cost: 0.10705367712590994\n",
            "\n",
            "Iteration: 643/1000\n",
            "Cost: 0.10705367497910805\n",
            "\n",
            "Iteration: 644/1000\n",
            "Cost: 0.10705367286163621\n",
            "\n",
            "Iteration: 645/1000\n",
            "Cost: 0.10705367077309605\n",
            "\n",
            "Iteration: 646/1000\n",
            "Cost: 0.10705366871309437\n",
            "\n",
            "Iteration: 647/1000\n",
            "Cost: 0.10705366668124335\n",
            "\n",
            "Iteration: 648/1000\n",
            "Cost: 0.10705366467716042\n",
            "\n",
            "Iteration: 649/1000\n",
            "Cost: 0.10705366270046836\n",
            "\n",
            "Iteration: 650/1000\n",
            "Cost: 0.10705366075079491\n",
            "\n",
            "Iteration: 651/1000\n",
            "Cost: 0.10705365882777292\n",
            "\n",
            "Iteration: 652/1000\n",
            "Cost: 0.10705365693104045\n",
            "\n",
            "Iteration: 653/1000\n",
            "Cost: 0.10705365506023998\n",
            "\n",
            "Iteration: 654/1000\n",
            "Cost: 0.10705365321501929\n",
            "\n",
            "Iteration: 655/1000\n",
            "Cost: 0.10705365139503091\n",
            "\n",
            "Iteration: 656/1000\n",
            "Cost: 0.10705364959993176\n",
            "\n",
            "Iteration: 657/1000\n",
            "Cost: 0.10705364782938374\n",
            "\n",
            "Iteration: 658/1000\n",
            "Cost: 0.10705364608305329\n",
            "\n",
            "Iteration: 659/1000\n",
            "Cost: 0.10705364436061136\n",
            "\n",
            "Iteration: 660/1000\n",
            "Cost: 0.10705364266173314\n",
            "\n",
            "Iteration: 661/1000\n",
            "Cost: 0.1070536409860987\n",
            "\n",
            "Iteration: 662/1000\n",
            "Cost: 0.10705363933339204\n",
            "\n",
            "Iteration: 663/1000\n",
            "Cost: 0.10705363770330166\n",
            "\n",
            "Iteration: 664/1000\n",
            "Cost: 0.10705363609552018\n",
            "\n",
            "Iteration: 665/1000\n",
            "Cost: 0.1070536345097445\n",
            "\n",
            "Iteration: 666/1000\n",
            "Cost: 0.10705363294567558\n",
            "\n",
            "Iteration: 667/1000\n",
            "Cost: 0.10705363140301842\n",
            "\n",
            "Iteration: 668/1000\n",
            "Cost: 0.10705362988148216\n",
            "\n",
            "Iteration: 669/1000\n",
            "Cost: 0.10705362838077953\n",
            "\n",
            "Iteration: 670/1000\n",
            "Cost: 0.10705362690062761\n",
            "\n",
            "Iteration: 671/1000\n",
            "Cost: 0.10705362544074705\n",
            "\n",
            "Iteration: 672/1000\n",
            "Cost: 0.10705362400086235\n",
            "\n",
            "Iteration: 673/1000\n",
            "Cost: 0.1070536225807019\n",
            "\n",
            "Iteration: 674/1000\n",
            "Cost: 0.10705362117999738\n",
            "\n",
            "Iteration: 675/1000\n",
            "Cost: 0.10705361979848448\n",
            "\n",
            "Iteration: 676/1000\n",
            "Cost: 0.10705361843590247\n",
            "\n",
            "Iteration: 677/1000\n",
            "Cost: 0.10705361709199397\n",
            "\n",
            "Iteration: 678/1000\n",
            "Cost: 0.10705361576650509\n",
            "\n",
            "Iteration: 679/1000\n",
            "Cost: 0.10705361445918565\n",
            "\n",
            "Iteration: 680/1000\n",
            "Cost: 0.1070536131697885\n",
            "\n",
            "Iteration: 681/1000\n",
            "Cost: 0.10705361189807014\n",
            "\n",
            "Iteration: 682/1000\n",
            "Cost: 0.10705361064379022\n",
            "\n",
            "Iteration: 683/1000\n",
            "Cost: 0.1070536094067116\n",
            "\n",
            "Iteration: 684/1000\n",
            "Cost: 0.10705360818660069\n",
            "\n",
            "Iteration: 685/1000\n",
            "Cost: 0.10705360698322669\n",
            "\n",
            "Iteration: 686/1000\n",
            "Cost: 0.10705360579636197\n",
            "\n",
            "Iteration: 687/1000\n",
            "Cost: 0.10705360462578217\n",
            "\n",
            "Iteration: 688/1000\n",
            "Cost: 0.107053603471266\n",
            "\n",
            "Iteration: 689/1000\n",
            "Cost: 0.10705360233259484\n",
            "\n",
            "Iteration: 690/1000\n",
            "Cost: 0.10705360120955348\n",
            "\n",
            "Iteration: 691/1000\n",
            "Cost: 0.10705360010192917\n",
            "\n",
            "Iteration: 692/1000\n",
            "Cost: 0.10705359900951246\n",
            "\n",
            "Iteration: 693/1000\n",
            "Cost: 0.1070535979320965\n",
            "\n",
            "Iteration: 694/1000\n",
            "Cost: 0.1070535968694773\n",
            "\n",
            "Iteration: 695/1000\n",
            "Cost: 0.10705359582145363\n",
            "\n",
            "Iteration: 696/1000\n",
            "Cost: 0.10705359478782708\n",
            "\n",
            "Iteration: 697/1000\n",
            "Cost: 0.10705359376840169\n",
            "\n",
            "Iteration: 698/1000\n",
            "Cost: 0.10705359276298447\n",
            "\n",
            "Iteration: 699/1000\n",
            "Cost: 0.10705359177138488\n",
            "\n",
            "Iteration: 700/1000\n",
            "Cost: 0.10705359079341496\n",
            "\n",
            "Iteration: 701/1000\n",
            "Cost: 0.1070535898288892\n",
            "\n",
            "Iteration: 702/1000\n",
            "Cost: 0.10705358887762481\n",
            "\n",
            "Iteration: 703/1000\n",
            "Cost: 0.1070535879394415\n",
            "\n",
            "Iteration: 704/1000\n",
            "Cost: 0.10705358701416116\n",
            "\n",
            "Iteration: 705/1000\n",
            "Cost: 0.10705358610160828\n",
            "\n",
            "Iteration: 706/1000\n",
            "Cost: 0.10705358520160968\n",
            "\n",
            "Iteration: 707/1000\n",
            "Cost: 0.10705358431399475\n",
            "\n",
            "Iteration: 708/1000\n",
            "Cost: 0.10705358343859475\n",
            "\n",
            "Iteration: 709/1000\n",
            "Cost: 0.10705358257524343\n",
            "\n",
            "Iteration: 710/1000\n",
            "Cost: 0.10705358172377705\n",
            "\n",
            "Iteration: 711/1000\n",
            "Cost: 0.10705358088403372\n",
            "\n",
            "Iteration: 712/1000\n",
            "Cost: 0.10705358005585396\n",
            "\n",
            "Iteration: 713/1000\n",
            "Cost: 0.10705357923908036\n",
            "\n",
            "Iteration: 714/1000\n",
            "Cost: 0.1070535784335577\n",
            "\n",
            "Iteration: 715/1000\n",
            "Cost: 0.1070535776391328\n",
            "\n",
            "Iteration: 716/1000\n",
            "Cost: 0.10705357685565464\n",
            "\n",
            "Iteration: 717/1000\n",
            "Cost: 0.10705357608297411\n",
            "\n",
            "Iteration: 718/1000\n",
            "Cost: 0.10705357532094424\n",
            "\n",
            "Iteration: 719/1000\n",
            "Cost: 0.10705357456942013\n",
            "\n",
            "Iteration: 720/1000\n",
            "Cost: 0.10705357382825857\n",
            "\n",
            "Iteration: 721/1000\n",
            "Cost: 0.10705357309731857\n",
            "\n",
            "Iteration: 722/1000\n",
            "Cost: 0.1070535723764609\n",
            "\n",
            "Iteration: 723/1000\n",
            "Cost: 0.10705357166554819\n",
            "\n",
            "Iteration: 724/1000\n",
            "Cost: 0.10705357096444518\n",
            "\n",
            "Iteration: 725/1000\n",
            "Cost: 0.10705357027301815\n",
            "\n",
            "Iteration: 726/1000\n",
            "Cost: 0.10705356959113523\n",
            "\n",
            "Iteration: 727/1000\n",
            "Cost: 0.10705356891866642\n",
            "\n",
            "Iteration: 728/1000\n",
            "Cost: 0.1070535682554837\n",
            "\n",
            "Iteration: 729/1000\n",
            "Cost: 0.10705356760146031\n",
            "\n",
            "Iteration: 730/1000\n",
            "Cost: 0.10705356695647152\n",
            "\n",
            "Iteration: 731/1000\n",
            "Cost: 0.1070535663203942\n",
            "\n",
            "Iteration: 732/1000\n",
            "Cost: 0.10705356569310712\n",
            "\n",
            "Iteration: 733/1000\n",
            "Cost: 0.10705356507449015\n",
            "\n",
            "Iteration: 734/1000\n",
            "Cost: 0.10705356446442536\n",
            "\n",
            "Iteration: 735/1000\n",
            "Cost: 0.10705356386279619\n",
            "\n",
            "Iteration: 736/1000\n",
            "Cost: 0.10705356326948764\n",
            "\n",
            "Iteration: 737/1000\n",
            "Cost: 0.10705356268438611\n",
            "\n",
            "Iteration: 738/1000\n",
            "Cost: 0.10705356210737996\n",
            "\n",
            "Iteration: 739/1000\n",
            "Cost: 0.1070535615383586\n",
            "\n",
            "Iteration: 740/1000\n",
            "Cost: 0.10705356097721336\n",
            "\n",
            "Iteration: 741/1000\n",
            "Cost: 0.10705356042383675\n",
            "\n",
            "Iteration: 742/1000\n",
            "Cost: 0.10705355987812273\n",
            "\n",
            "Iteration: 743/1000\n",
            "Cost: 0.10705355933996688\n",
            "\n",
            "Iteration: 744/1000\n",
            "Cost: 0.10705355880926616\n",
            "\n",
            "Iteration: 745/1000\n",
            "Cost: 0.10705355828591881\n",
            "\n",
            "Iteration: 746/1000\n",
            "Cost: 0.10705355776982453\n",
            "\n",
            "Iteration: 747/1000\n",
            "Cost: 0.10705355726088452\n",
            "\n",
            "Iteration: 748/1000\n",
            "Cost: 0.10705355675900084\n",
            "\n",
            "Iteration: 749/1000\n",
            "Cost: 0.10705355626407742\n",
            "\n",
            "Iteration: 750/1000\n",
            "Cost: 0.1070535557760193\n",
            "\n",
            "Iteration: 751/1000\n",
            "Cost: 0.10705355529473257\n",
            "\n",
            "Iteration: 752/1000\n",
            "Cost: 0.10705355482012512\n",
            "\n",
            "Iteration: 753/1000\n",
            "Cost: 0.10705355435210546\n",
            "\n",
            "Iteration: 754/1000\n",
            "Cost: 0.10705355389058388\n",
            "\n",
            "Iteration: 755/1000\n",
            "Cost: 0.10705355343547154\n",
            "\n",
            "Iteration: 756/1000\n",
            "Cost: 0.107053552986681\n",
            "\n",
            "Iteration: 757/1000\n",
            "Cost: 0.10705355254412588\n",
            "\n",
            "Iteration: 758/1000\n",
            "Cost: 0.10705355210772112\n",
            "\n",
            "Iteration: 759/1000\n",
            "Cost: 0.10705355167738256\n",
            "\n",
            "Iteration: 760/1000\n",
            "Cost: 0.1070535512530274\n",
            "\n",
            "Iteration: 761/1000\n",
            "Cost: 0.107053550834574\n",
            "\n",
            "Iteration: 762/1000\n",
            "Cost: 0.10705355042194155\n",
            "\n",
            "Iteration: 763/1000\n",
            "Cost: 0.1070535500150506\n",
            "\n",
            "Iteration: 764/1000\n",
            "Cost: 0.10705354961382277\n",
            "\n",
            "Iteration: 765/1000\n",
            "Cost: 0.10705354921818061\n",
            "\n",
            "Iteration: 766/1000\n",
            "Cost: 0.10705354882804763\n",
            "\n",
            "Iteration: 767/1000\n",
            "Cost: 0.10705354844334873\n",
            "\n",
            "Iteration: 768/1000\n",
            "Cost: 0.10705354806400944\n",
            "\n",
            "Iteration: 769/1000\n",
            "Cost: 0.10705354768995669\n",
            "\n",
            "Iteration: 770/1000\n",
            "Cost: 0.10705354732111798\n",
            "\n",
            "Iteration: 771/1000\n",
            "Cost: 0.10705354695742218\n",
            "\n",
            "Iteration: 772/1000\n",
            "Cost: 0.10705354659879873\n",
            "\n",
            "Iteration: 773/1000\n",
            "Cost: 0.10705354624517843\n",
            "\n",
            "Iteration: 774/1000\n",
            "Cost: 0.10705354589649284\n",
            "\n",
            "Iteration: 775/1000\n",
            "Cost: 0.1070535455526743\n",
            "\n",
            "Iteration: 776/1000\n",
            "Cost: 0.1070535452136563\n",
            "\n",
            "Iteration: 777/1000\n",
            "Cost: 0.10705354487937319\n",
            "\n",
            "Iteration: 778/1000\n",
            "Cost: 0.10705354454976013\n",
            "\n",
            "Iteration: 779/1000\n",
            "Cost: 0.10705354422475309\n",
            "\n",
            "Iteration: 780/1000\n",
            "Cost: 0.10705354390428919\n",
            "\n",
            "Iteration: 781/1000\n",
            "Cost: 0.10705354358830602\n",
            "\n",
            "Iteration: 782/1000\n",
            "Cost: 0.10705354327674238\n",
            "\n",
            "Iteration: 783/1000\n",
            "Cost: 0.10705354296953776\n",
            "\n",
            "Iteration: 784/1000\n",
            "Cost: 0.10705354266663226\n",
            "\n",
            "Iteration: 785/1000\n",
            "Cost: 0.10705354236796727\n",
            "\n",
            "Iteration: 786/1000\n",
            "Cost: 0.10705354207348437\n",
            "\n",
            "Iteration: 787/1000\n",
            "Cost: 0.10705354178312651\n",
            "\n",
            "Iteration: 788/1000\n",
            "Cost: 0.10705354149683709\n",
            "\n",
            "Iteration: 789/1000\n",
            "Cost: 0.1070535412145603\n",
            "\n",
            "Iteration: 790/1000\n",
            "Cost: 0.10705354093624114\n",
            "\n",
            "Iteration: 791/1000\n",
            "Cost: 0.10705354066182546\n",
            "\n",
            "Iteration: 792/1000\n",
            "Cost: 0.1070535403912595\n",
            "\n",
            "Iteration: 793/1000\n",
            "Cost: 0.10705354012449078\n",
            "\n",
            "Iteration: 794/1000\n",
            "Cost: 0.10705353986146693\n",
            "\n",
            "Iteration: 795/1000\n",
            "Cost: 0.10705353960213677\n",
            "\n",
            "Iteration: 796/1000\n",
            "Cost: 0.10705353934644954\n",
            "\n",
            "Iteration: 797/1000\n",
            "Cost: 0.1070535390943553\n",
            "\n",
            "Iteration: 798/1000\n",
            "Cost: 0.10705353884580471\n",
            "\n",
            "Iteration: 799/1000\n",
            "Cost: 0.1070535386007491\n",
            "\n",
            "Iteration: 800/1000\n",
            "Cost: 0.10705353835914055\n",
            "\n",
            "Iteration: 801/1000\n",
            "Cost: 0.10705353812093174\n",
            "\n",
            "Iteration: 802/1000\n",
            "Cost: 0.10705353788607587\n",
            "\n",
            "Iteration: 803/1000\n",
            "Cost: 0.10705353765452713\n",
            "\n",
            "Iteration: 804/1000\n",
            "Cost: 0.10705353742623977\n",
            "\n",
            "Iteration: 805/1000\n",
            "Cost: 0.10705353720116925\n",
            "\n",
            "Iteration: 806/1000\n",
            "Cost: 0.1070535369792713\n",
            "\n",
            "Iteration: 807/1000\n",
            "Cost: 0.10705353676050235\n",
            "\n",
            "Iteration: 808/1000\n",
            "Cost: 0.10705353654481932\n",
            "\n",
            "Iteration: 809/1000\n",
            "Cost: 0.10705353633217977\n",
            "\n",
            "Iteration: 810/1000\n",
            "Cost: 0.1070535361225419\n",
            "\n",
            "Iteration: 811/1000\n",
            "Cost: 0.10705353591586445\n",
            "\n",
            "Iteration: 812/1000\n",
            "Cost: 0.10705353571210682\n",
            "\n",
            "Iteration: 813/1000\n",
            "Cost: 0.10705353551122863\n",
            "\n",
            "Iteration: 814/1000\n",
            "Cost: 0.10705353531319034\n",
            "\n",
            "Iteration: 815/1000\n",
            "Cost: 0.10705353511795294\n",
            "\n",
            "Iteration: 816/1000\n",
            "Cost: 0.10705353492547777\n",
            "\n",
            "Iteration: 817/1000\n",
            "Cost: 0.1070535347357269\n",
            "\n",
            "Iteration: 818/1000\n",
            "Cost: 0.10705353454866288\n",
            "\n",
            "Iteration: 819/1000\n",
            "Cost: 0.10705353436424858\n",
            "\n",
            "Iteration: 820/1000\n",
            "Cost: 0.10705353418244755\n",
            "\n",
            "Iteration: 821/1000\n",
            "Cost: 0.10705353400322384\n",
            "\n",
            "Iteration: 822/1000\n",
            "Cost: 0.10705353382654183\n",
            "\n",
            "Iteration: 823/1000\n",
            "Cost: 0.10705353365236665\n",
            "\n",
            "Iteration: 824/1000\n",
            "Cost: 0.10705353348066363\n",
            "\n",
            "Iteration: 825/1000\n",
            "Cost: 0.10705353331139884\n",
            "\n",
            "Iteration: 826/1000\n",
            "Cost: 0.10705353314453854\n",
            "\n",
            "Iteration: 827/1000\n",
            "Cost: 0.1070535329800496\n",
            "\n",
            "Iteration: 828/1000\n",
            "Cost: 0.1070535328178993\n",
            "\n",
            "Iteration: 829/1000\n",
            "Cost: 0.10705353265805542\n",
            "\n",
            "Iteration: 830/1000\n",
            "Cost: 0.10705353250048608\n",
            "\n",
            "Iteration: 831/1000\n",
            "Cost: 0.10705353234515992\n",
            "\n",
            "Iteration: 832/1000\n",
            "Cost: 0.10705353219204601\n",
            "\n",
            "Iteration: 833/1000\n",
            "Cost: 0.10705353204111387\n",
            "\n",
            "Iteration: 834/1000\n",
            "Cost: 0.10705353189233323\n",
            "\n",
            "Iteration: 835/1000\n",
            "Cost: 0.10705353174567439\n",
            "\n",
            "Iteration: 836/1000\n",
            "Cost: 0.10705353160110817\n",
            "\n",
            "Iteration: 837/1000\n",
            "Cost: 0.10705353145860559\n",
            "\n",
            "Iteration: 838/1000\n",
            "Cost: 0.10705353131813804\n",
            "\n",
            "Iteration: 839/1000\n",
            "Cost: 0.10705353117967756\n",
            "\n",
            "Iteration: 840/1000\n",
            "Cost: 0.10705353104319623\n",
            "\n",
            "Iteration: 841/1000\n",
            "Cost: 0.10705353090866687\n",
            "\n",
            "Iteration: 842/1000\n",
            "Cost: 0.10705353077606237\n",
            "\n",
            "Iteration: 843/1000\n",
            "Cost: 0.1070535306453561\n",
            "\n",
            "Iteration: 844/1000\n",
            "Cost: 0.10705353051652179\n",
            "\n",
            "Iteration: 845/1000\n",
            "Cost: 0.10705353038953369\n",
            "\n",
            "Iteration: 846/1000\n",
            "Cost: 0.10705353026436602\n",
            "\n",
            "Iteration: 847/1000\n",
            "Cost: 0.10705353014099366\n",
            "\n",
            "Iteration: 848/1000\n",
            "Cost: 0.10705353001939183\n",
            "\n",
            "Iteration: 849/1000\n",
            "Cost: 0.10705352989953587\n",
            "\n",
            "Iteration: 850/1000\n",
            "Cost: 0.10705352978140167\n",
            "\n",
            "Iteration: 851/1000\n",
            "Cost: 0.10705352966496538\n",
            "\n",
            "Iteration: 852/1000\n",
            "Cost: 0.1070535295502035\n",
            "\n",
            "Iteration: 853/1000\n",
            "Cost: 0.10705352943709262\n",
            "\n",
            "Iteration: 854/1000\n",
            "Cost: 0.10705352932561017\n",
            "\n",
            "Iteration: 855/1000\n",
            "Cost: 0.10705352921573327\n",
            "\n",
            "Iteration: 856/1000\n",
            "Cost: 0.10705352910743979\n",
            "\n",
            "Iteration: 857/1000\n",
            "Cost: 0.10705352900070773\n",
            "\n",
            "Iteration: 858/1000\n",
            "Cost: 0.10705352889551543\n",
            "\n",
            "Iteration: 859/1000\n",
            "Cost: 0.10705352879184157\n",
            "\n",
            "Iteration: 860/1000\n",
            "Cost: 0.1070535286896649\n",
            "\n",
            "Iteration: 861/1000\n",
            "Cost: 0.1070535285889648\n",
            "\n",
            "Iteration: 862/1000\n",
            "Cost: 0.10705352848972055\n",
            "\n",
            "Iteration: 863/1000\n",
            "Cost: 0.10705352839191214\n",
            "\n",
            "Iteration: 864/1000\n",
            "Cost: 0.10705352829551947\n",
            "\n",
            "Iteration: 865/1000\n",
            "Cost: 0.10705352820052293\n",
            "\n",
            "Iteration: 866/1000\n",
            "Cost: 0.107053528106903\n",
            "\n",
            "Iteration: 867/1000\n",
            "Cost: 0.10705352801464073\n",
            "\n",
            "Iteration: 868/1000\n",
            "Cost: 0.10705352792371708\n",
            "\n",
            "Iteration: 869/1000\n",
            "Cost: 0.10705352783411333\n",
            "\n",
            "Iteration: 870/1000\n",
            "Cost: 0.1070535277458113\n",
            "\n",
            "Iteration: 871/1000\n",
            "Cost: 0.10705352765879271\n",
            "\n",
            "Iteration: 872/1000\n",
            "Cost: 0.10705352757303985\n",
            "\n",
            "Iteration: 873/1000\n",
            "Cost: 0.1070535274885349\n",
            "\n",
            "Iteration: 874/1000\n",
            "Cost: 0.10705352740526063\n",
            "\n",
            "Iteration: 875/1000\n",
            "Cost: 0.1070535273231998\n",
            "\n",
            "Iteration: 876/1000\n",
            "Cost: 0.10705352724233547\n",
            "\n",
            "Iteration: 877/1000\n",
            "Cost: 0.10705352716265092\n",
            "\n",
            "Iteration: 878/1000\n",
            "Cost: 0.10705352708412981\n",
            "\n",
            "Iteration: 879/1000\n",
            "Cost: 0.1070535270067559\n",
            "\n",
            "Iteration: 880/1000\n",
            "Cost: 0.10705352693051305\n",
            "\n",
            "Iteration: 881/1000\n",
            "Cost: 0.10705352685538552\n",
            "\n",
            "Iteration: 882/1000\n",
            "Cost: 0.10705352678135777\n",
            "\n",
            "Iteration: 883/1000\n",
            "Cost: 0.10705352670841448\n",
            "\n",
            "Iteration: 884/1000\n",
            "Cost: 0.10705352663654033\n",
            "\n",
            "Iteration: 885/1000\n",
            "Cost: 0.10705352656572051\n",
            "\n",
            "Iteration: 886/1000\n",
            "Cost: 0.10705352649594015\n",
            "\n",
            "Iteration: 887/1000\n",
            "Cost: 0.10705352642718485\n",
            "\n",
            "Iteration: 888/1000\n",
            "Cost: 0.10705352635944022\n",
            "\n",
            "Iteration: 889/1000\n",
            "Cost: 0.10705352629269207\n",
            "\n",
            "Iteration: 890/1000\n",
            "Cost: 0.10705352622692649\n",
            "\n",
            "Iteration: 891/1000\n",
            "Cost: 0.1070535261621297\n",
            "\n",
            "Iteration: 892/1000\n",
            "Cost: 0.10705352609828815\n",
            "\n",
            "Iteration: 893/1000\n",
            "Cost: 0.10705352603538841\n",
            "\n",
            "Iteration: 894/1000\n",
            "Cost: 0.10705352597341734\n",
            "\n",
            "Iteration: 895/1000\n",
            "Cost: 0.10705352591236192\n",
            "\n",
            "Iteration: 896/1000\n",
            "Cost: 0.10705352585220927\n",
            "\n",
            "Iteration: 897/1000\n",
            "Cost: 0.10705352579294652\n",
            "\n",
            "Iteration: 898/1000\n",
            "Cost: 0.10705352573456153\n",
            "\n",
            "Iteration: 899/1000\n",
            "Cost: 0.10705352567704182\n",
            "\n",
            "Iteration: 900/1000\n",
            "Cost: 0.10705352562037523\n",
            "\n",
            "Iteration: 901/1000\n",
            "Cost: 0.10705352556454974\n",
            "\n",
            "Iteration: 902/1000\n",
            "Cost: 0.10705352550955356\n",
            "\n",
            "Iteration: 903/1000\n",
            "Cost: 0.10705352545537512\n",
            "\n",
            "Iteration: 904/1000\n",
            "Cost: 0.10705352540200277\n",
            "\n",
            "Iteration: 905/1000\n",
            "Cost: 0.1070535253494252\n",
            "\n",
            "Iteration: 906/1000\n",
            "Cost: 0.10705352529763132\n",
            "\n",
            "Iteration: 907/1000\n",
            "Cost: 0.10705352524660995\n",
            "\n",
            "Iteration: 908/1000\n",
            "Cost: 0.10705352519635038\n",
            "\n",
            "Iteration: 909/1000\n",
            "Cost: 0.1070535251468417\n",
            "\n",
            "Iteration: 910/1000\n",
            "Cost: 0.10705352509807341\n",
            "\n",
            "Iteration: 911/1000\n",
            "Cost: 0.10705352505003518\n",
            "\n",
            "Iteration: 912/1000\n",
            "Cost: 0.10705352500271653\n",
            "\n",
            "Iteration: 913/1000\n",
            "Cost: 0.10705352495610734\n",
            "\n",
            "Iteration: 914/1000\n",
            "Cost: 0.10705352491019769\n",
            "\n",
            "Iteration: 915/1000\n",
            "Cost: 0.10705352486497766\n",
            "\n",
            "Iteration: 916/1000\n",
            "Cost: 0.10705352482043738\n",
            "\n",
            "Iteration: 917/1000\n",
            "Cost: 0.10705352477656743\n",
            "\n",
            "Iteration: 918/1000\n",
            "Cost: 0.10705352473335826\n",
            "\n",
            "Iteration: 919/1000\n",
            "Cost: 0.10705352469080057\n",
            "\n",
            "Iteration: 920/1000\n",
            "Cost: 0.10705352464888501\n",
            "\n",
            "Iteration: 921/1000\n",
            "Cost: 0.10705352460760262\n",
            "\n",
            "Iteration: 922/1000\n",
            "Cost: 0.10705352456694432\n",
            "\n",
            "Iteration: 923/1000\n",
            "Cost: 0.10705352452690145\n",
            "\n",
            "Iteration: 924/1000\n",
            "Cost: 0.10705352448746516\n",
            "\n",
            "Iteration: 925/1000\n",
            "Cost: 0.10705352444862676\n",
            "\n",
            "Iteration: 926/1000\n",
            "Cost: 0.10705352441037803\n",
            "\n",
            "Iteration: 927/1000\n",
            "Cost: 0.10705352437271029\n",
            "\n",
            "Iteration: 928/1000\n",
            "Cost: 0.10705352433561557\n",
            "\n",
            "Iteration: 929/1000\n",
            "Cost: 0.10705352429908556\n",
            "\n",
            "Iteration: 930/1000\n",
            "Cost: 0.10705352426311239\n",
            "\n",
            "Iteration: 931/1000\n",
            "Cost: 0.10705352422768791\n",
            "\n",
            "Iteration: 932/1000\n",
            "Cost: 0.10705352419280445\n",
            "\n",
            "Iteration: 933/1000\n",
            "Cost: 0.10705352415845448\n",
            "\n",
            "Iteration: 934/1000\n",
            "Cost: 0.10705352412463015\n",
            "\n",
            "Iteration: 935/1000\n",
            "Cost: 0.10705352409132411\n",
            "\n",
            "Iteration: 936/1000\n",
            "Cost: 0.10705352405852891\n",
            "\n",
            "Iteration: 937/1000\n",
            "Cost: 0.10705352402623734\n",
            "\n",
            "Iteration: 938/1000\n",
            "Cost: 0.10705352399444211\n",
            "\n",
            "Iteration: 939/1000\n",
            "Cost: 0.10705352396313624\n",
            "\n",
            "Iteration: 940/1000\n",
            "Cost: 0.10705352393231275\n",
            "\n",
            "Iteration: 941/1000\n",
            "Cost: 0.10705352390196474\n",
            "\n",
            "Iteration: 942/1000\n",
            "Cost: 0.1070535238720854\n",
            "\n",
            "Iteration: 943/1000\n",
            "Cost: 0.10705352384266793\n",
            "\n",
            "Iteration: 944/1000\n",
            "Cost: 0.10705352381370598\n",
            "\n",
            "Iteration: 945/1000\n",
            "Cost: 0.10705352378519283\n",
            "\n",
            "Iteration: 946/1000\n",
            "Cost: 0.10705352375712202\n",
            "\n",
            "Iteration: 947/1000\n",
            "Cost: 0.10705352372948733\n",
            "\n",
            "Iteration: 948/1000\n",
            "Cost: 0.10705352370228262\n",
            "\n",
            "Iteration: 949/1000\n",
            "Cost: 0.10705352367550156\n",
            "\n",
            "Iteration: 950/1000\n",
            "Cost: 0.10705352364913807\n",
            "\n",
            "Iteration: 951/1000\n",
            "Cost: 0.10705352362318621\n",
            "\n",
            "Iteration: 952/1000\n",
            "Cost: 0.10705352359764009\n",
            "\n",
            "Iteration: 953/1000\n",
            "Cost: 0.10705352357249381\n",
            "\n",
            "Iteration: 954/1000\n",
            "Cost: 0.10705352354774172\n",
            "\n",
            "Iteration: 955/1000\n",
            "Cost: 0.10705352352337814\n",
            "\n",
            "Iteration: 956/1000\n",
            "Cost: 0.1070535234993974\n",
            "\n",
            "Iteration: 957/1000\n",
            "Cost: 0.1070535234757941\n",
            "\n",
            "Iteration: 958/1000\n",
            "Cost: 0.10705352345256265\n",
            "\n",
            "Iteration: 959/1000\n",
            "Cost: 0.10705352342969779\n",
            "\n",
            "Iteration: 960/1000\n",
            "Cost: 0.10705352340719425\n",
            "\n",
            "Iteration: 961/1000\n",
            "Cost: 0.10705352338504687\n",
            "\n",
            "Iteration: 962/1000\n",
            "Cost: 0.10705352336325041\n",
            "\n",
            "Iteration: 963/1000\n",
            "Cost: 0.10705352334179992\n",
            "\n",
            "Iteration: 964/1000\n",
            "Cost: 0.1070535233206902\n",
            "\n",
            "Iteration: 965/1000\n",
            "Cost: 0.10705352329991648\n",
            "\n",
            "Iteration: 966/1000\n",
            "Cost: 0.10705352327947386\n",
            "\n",
            "Iteration: 967/1000\n",
            "Cost: 0.10705352325935759\n",
            "\n",
            "Iteration: 968/1000\n",
            "Cost: 0.10705352323956291\n",
            "\n",
            "Iteration: 969/1000\n",
            "Cost: 0.10705352322008503\n",
            "\n",
            "Iteration: 970/1000\n",
            "Cost: 0.10705352320091964\n",
            "\n",
            "Iteration: 971/1000\n",
            "Cost: 0.10705352318206204\n",
            "\n",
            "Iteration: 972/1000\n",
            "Cost: 0.10705352316350766\n",
            "\n",
            "Iteration: 973/1000\n",
            "Cost: 0.10705352314525238\n",
            "\n",
            "Iteration: 974/1000\n",
            "Cost: 0.1070535231272916\n",
            "\n",
            "Iteration: 975/1000\n",
            "Cost: 0.10705352310962113\n",
            "\n",
            "Iteration: 976/1000\n",
            "Cost: 0.10705352309223667\n",
            "\n",
            "Iteration: 977/1000\n",
            "Cost: 0.10705352307513424\n",
            "\n",
            "Iteration: 978/1000\n",
            "Cost: 0.10705352305830962\n",
            "\n",
            "Iteration: 979/1000\n",
            "Cost: 0.1070535230417587\n",
            "\n",
            "Iteration: 980/1000\n",
            "Cost: 0.10705352302547756\n",
            "\n",
            "Iteration: 981/1000\n",
            "Cost: 0.10705352300946226\n",
            "\n",
            "Iteration: 982/1000\n",
            "Cost: 0.10705352299370886\n",
            "\n",
            "Iteration: 983/1000\n",
            "Cost: 0.10705352297821369\n",
            "\n",
            "Iteration: 984/1000\n",
            "Cost: 0.10705352296297273\n",
            "\n",
            "Iteration: 985/1000\n",
            "Cost: 0.10705352294798255\n",
            "\n",
            "Iteration: 986/1000\n",
            "Cost: 0.10705352293323916\n",
            "\n",
            "Iteration: 987/1000\n",
            "Cost: 0.1070535229187392\n",
            "\n",
            "Iteration: 988/1000\n",
            "Cost: 0.10705352290447896\n",
            "\n",
            "Iteration: 989/1000\n",
            "Cost: 0.10705352289045503\n",
            "\n",
            "Iteration: 990/1000\n",
            "Cost: 0.1070535228766638\n",
            "\n",
            "Iteration: 991/1000\n",
            "Cost: 0.10705352286310195\n",
            "\n",
            "Iteration: 992/1000\n",
            "Cost: 0.10705352284976617\n",
            "\n",
            "Iteration: 993/1000\n",
            "Cost: 0.10705352283665297\n",
            "\n",
            "Iteration: 994/1000\n",
            "Cost: 0.10705352282375917\n",
            "\n",
            "Iteration: 995/1000\n",
            "Cost: 0.10705352281108141\n",
            "\n",
            "Iteration: 996/1000\n",
            "Cost: 0.10705352279861671\n",
            "\n",
            "Iteration: 997/1000\n",
            "Cost: 0.10705352278636186\n",
            "\n",
            "Iteration: 998/1000\n",
            "Cost: 0.10705352277431371\n",
            "\n",
            "Iteration: 999/1000\n",
            "Cost: 0.10705352276246913\n",
            "\n",
            "Iteration: 1000/1000\n",
            "Cost: 0.10705352275082523\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initializing the numpy model and training it for 1000 iterations\n",
        "numpy_model = LogisticRegression_(iterations=1000, alpha=5, degree=2)\n",
        "numpy_model.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "o4qQeQ8fwc9t",
        "outputId": "cb21aed0-bbe1-4546-a413-320e0c47efb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Cost')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting the training history of the model\n",
        "history = np.array(numpy_model.history)\n",
        "\n",
        "plt.plot(history[:, 0], history[:, 1])\n",
        "plt.title(\"Iterations vs Cost\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Cost\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbFwKjZjwt2n"
      },
      "source": [
        "As we can see in the above plot that cost has been minimized, thus resulting in optimal parameters for the model. Now we are ready to make prediction. We will make prediction on all sets and compare the results with scikit-learn model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oEidnRfwhM3",
        "outputId": "303be63b-7079-4a04-8f6e-036c534b8965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.9663\n",
            "Cross-Validation Accuracy: 0.9706\n",
            "Test Accuracy: 0.9550\n"
          ]
        }
      ],
      "source": [
        "# Making prediction on all sets and calculating the accuracy\n",
        "train_accuracy_ = accuracy_score(Y_train, (numpy_model.make_prediction(X_train) >= 0.5).astype(int))\n",
        "cv_accuracy_ = accuracy_score(Y_cv, (numpy_model.make_prediction(X_cv) >= 0.5).astype(int))\n",
        "test_accuracy_ = accuracy_score(Y_test, (numpy_model.make_prediction(X_test) >= 0.5).astype(int))\n",
        "\n",
        "print(f\"Train Accuracy: {train_accuracy_:.4f}\"),\n",
        "print(f\"Cross-Validation Accuracy: {cv_accuracy_:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy_:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCH7GtrFyHme"
      },
      "source": [
        "The train and cross-validation accuracy of numpy model is slightly better than scikit-learn model, but for the test set the accuracy is same, thus marking the completion of building non-linear binary classification model using numpy library."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
